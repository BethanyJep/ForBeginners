{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Intro For Creators","text":"<p>This repository provides a template for building workshops or open-source curriculum in a way that complies with Microsoft open-source and compliance standards. </p> Project Objectives: click to expand <p>The project has three objectives:</p> <ol> <li>Instrument repos with a dev container to make setup fast and consistent</li> <li>Create an mkdocs website that can be hosted on GitHub pages</li> <li>Review for website compliance to get a Microsoft-approved baseline</li> </ol> <p>Once completed, this repository will be converted into a template with two base projects, one for each \"type\" of content delivery. Simply instantiate the template and refactor the identified folders to reflect your instructions and code samples.</p> Useful Resources: click to expand <p>This is a subset of documentation links that may be useful for creators to customize their docs:</p> <ol> <li>Blog Support - via plugin</li> <li>Internattionalization - custom translations</li> <li>Search Support - built-in plugin</li> <li>Admonitions - for highlighting actions</li> <li>Code Blocks - for inline snippets</li> </ol> <p>Why Use Mkdocs Material?</p> <p>The website is built with mkdocs-material to benefit from the following features:</p> <ol> <li>Python package - single dependency in <code>requirements.txt</code></li> <li>Easy configuration - single <code>mkdocs.yml</code> file</li> <li>Rich extensions - explore plugins and themes</li> <li>Built-in search - easy for learners to explore</li> <li>Built-in cookie consent - just add analytics tag</li> <li>Familiar content structure - markdown and folders</li> </ol>"},{"location":"#1-sample-rag-workshop","title":"1. Sample: RAG Workshop","text":"<p>This section contains the step-by-step instructions format that is suitable for delivering a workshop in events like the Microsoft AI Tour. </p> Template Objectives: click to expand <p>It provides guidance on setup and usage with Skillable, to allow learners to view a hosted version of workshop instructions (from your instance's GH pages) or launch their own preview within GitHuB Codespaces.</p> <p>It provides code steps in the form of src.sample/ folders where instructions simply ask learners to copy things over (too build from scratch) or reference inline (to understand code structures).</p>"},{"location":"#sample-agents-curriculum","title":"Sample: Agents Curriculum","text":"<p>This section contains the lesson-by-lesson coverage of a topic intended for self-guided learning in a curriculum format. </p> Template Objectives: click to expand <p>It provides exercises in the form of sample notebooks that learners can execute in GitHub Codespaces (where the content creator can ensure requirements are met with dev container configuration updates)</p>"},{"location":"#website-local-preview","title":"Website: Local Preview","text":"<p>This repository is instrumented with a <code>devcontainer.json</code> to give you a development environment with all required dependencies pre-installed. To get started:</p> Getting Started: click to expand <ol> <li>Fork the repository to your personal profile. Open fork in browser.</li> <li>Launch Codespaces on that fork. When ready, you see a VS Code IDE with Terminal.</li> <li> <p>Launch Local Preview of website. Type this command into VS Code terminal.</p> <pre><code>mkdocs serve\n</code></pre> </li> <li> <p>Select the \"View in browser\" option in the pop-up dialog. You should see this guide</p> </li> <li>Open a second VS Code terminal pane. Use that for all further instructions.</li> </ol>"},{"location":"Sample-Curriculum/01-Agent-Scenarios/01/","title":"01 | Introduction","text":"<p>Learning Objectives</p> <p>In this lesson, we'll answer the following questions:</p> <ul> <li>What are AI Agents and how are they different from Chat bots or assistants? </li> <li>How to design solutions where AI Agents would be useful? </li> <li>Where do I start and how do I cut through the noise and start building? </li> <li>What are the basic building blocks of building with Agents? </li> </ul>"},{"location":"Sample-Curriculum/01-Agent-Scenarios/01/#pre-requsites","title":"Pre-Requsites","text":""},{"location":"Sample-Curriculum/01-Agent-Scenarios/01/#learning-resources","title":"Learning Resources","text":""},{"location":"Sample-Curriculum/01-Agent-Scenarios/02/","title":"02 | Lesson","text":""},{"location":"Sample-Curriculum/01-Agent-Scenarios/03/","title":"03 | Lesson","text":""},{"location":"Sample-Curriculum/01-Agent-Scenarios/04/","title":"04 | Lesson","text":""},{"location":"Sample-Curriculum/01-Agent-Scenarios/05/","title":"05 | Lesson","text":""},{"location":"Sample-Curriculum/01-Agent-Scenarios/06/","title":"06 | Exercise","text":""},{"location":"Sample-Curriculum/01-Agent-Scenarios/07/","title":"07 | Summary","text":""},{"location":"Sample-Curriculum/02-Agent-Frameworks/01/","title":"01 | Introduction","text":"<p>Learning Objectives</p> <p>In this lesson, we'll answer the following questions:</p> <ul> <li>What are AI Agent Frameworks and what do they enable developers to do? </li> <li>How can teams use these to quickly prototype, iterate, and improve my agent\u2019s capabilities?</li> <li>What are the difference between the frameworks and tools created by Microsoft ( Autogen / Semantic Kernel / Azure AI Agent Service) </li> <li>Can I integrate my existing Azure ecosystem tools directly, or do I need standalone solutions?</li> </ul>"},{"location":"Sample-Curriculum/02-Agent-Frameworks/01/#pre-requsites","title":"Pre-Requsites","text":""},{"location":"Sample-Curriculum/02-Agent-Frameworks/01/#learning-resources","title":"Learning Resources","text":""},{"location":"Sample-Curriculum/02-Agent-Frameworks/02/","title":"02 | Lesson","text":""},{"location":"Sample-Curriculum/02-Agent-Frameworks/03/","title":"03 | Lesson","text":""},{"location":"Sample-Curriculum/02-Agent-Frameworks/04/","title":"04 | Lesson","text":""},{"location":"Sample-Curriculum/02-Agent-Frameworks/05/","title":"05 | Lesson","text":""},{"location":"Sample-Curriculum/02-Agent-Frameworks/06/","title":"06 | Exercise","text":""},{"location":"Sample-Curriculum/02-Agent-Frameworks/07/","title":"07 | Summary","text":""},{"location":"Sample-Curriculum/03-Design-Patterns/01/","title":"01 | Introduction","text":"<p>Learning Objectives</p> <p>In this lesson, we'll answer the following questions:</p> <ul> <li>What are Agentic Design Patterns? </li> <li>What are some examples (included in this course) and a brief description of them?</li> <li>What are the definitions of the key terms in Agentic Design Patterns? (ie- knowledge, memory and threads.</li> <li>What are some examples of how to apply these design patterns to an application? </li> <li>How do you decide which design pattern to use? </li> </ul>"},{"location":"Sample-Curriculum/03-Design-Patterns/01/#pre-requsites","title":"Pre-Requsites","text":""},{"location":"Sample-Curriculum/03-Design-Patterns/01/#learning-resources","title":"Learning Resources","text":""},{"location":"Sample-Curriculum/03-Design-Patterns/02/","title":"02 | Lesson","text":""},{"location":"Sample-Curriculum/03-Design-Patterns/03/","title":"03 | Lesson","text":""},{"location":"Sample-Curriculum/03-Design-Patterns/04/","title":"04 | Lesson","text":""},{"location":"Sample-Curriculum/03-Design-Patterns/05/","title":"05 | Lesson","text":""},{"location":"Sample-Curriculum/03-Design-Patterns/06/","title":"06 | Exercise","text":""},{"location":"Sample-Curriculum/03-Design-Patterns/07/","title":"07 | Summary","text":""},{"location":"Sample-Curriculum/04-Tool-Use/01/","title":"01 | Introduction","text":"<p>Learning Objectives</p> <p>In this lesson, we'll answer the following questions:</p> <ul> <li>What is the Tool Use Design Pattern? </li> <li>What are the use cases that it can be applied to? </li> <li>What are the elements/building blocks needed to implement the design pattern? </li> <li>What are special considerations for using the tool use design pattern to build trustworthy AI Agents? </li> </ul>"},{"location":"Sample-Curriculum/04-Tool-Use/01/#pre-requsites","title":"Pre-Requsites","text":""},{"location":"Sample-Curriculum/04-Tool-Use/01/#learning-resources","title":"Learning Resources","text":""},{"location":"Sample-Curriculum/04-Tool-Use/02/","title":"02 | Lesson","text":""},{"location":"Sample-Curriculum/04-Tool-Use/03/","title":"03 | Lesson","text":""},{"location":"Sample-Curriculum/04-Tool-Use/04/","title":"04 | Lesson","text":""},{"location":"Sample-Curriculum/04-Tool-Use/05/","title":"05 | Lesson","text":""},{"location":"Sample-Curriculum/04-Tool-Use/06/","title":"06 | Exercise","text":""},{"location":"Sample-Curriculum/04-Tool-Use/07/","title":"07 | Summary","text":""},{"location":"Sample-Curriculum/05-Agentic-RAG/01/","title":"01 | Introduction","text":"<p>Learning Objectives</p> <p>In this lesson, we'll answer the following questions:</p> <ul> <li>What is Agentic RAG and how is it different from the traditional RAG workflow? </li> <li>What are the elements/building blocks required for implementing Agentic RAG? </li> <li>How does evaluation change when implementing Agentic RAG? </li> <li>What is the technical architecture of an Agentic RAG workflow? </li> <li>What\u2019s the best approach to handle and integrate diverse data types (PDFs, images, audio) seamlessly?</li> </ul>"},{"location":"Sample-Curriculum/05-Agentic-RAG/01/#pre-requsites","title":"Pre-Requsites","text":""},{"location":"Sample-Curriculum/05-Agentic-RAG/01/#learning-resources","title":"Learning Resources","text":""},{"location":"Sample-Curriculum/05-Agentic-RAG/02/","title":"02 | Lesson","text":""},{"location":"Sample-Curriculum/05-Agentic-RAG/03/","title":"03 | Lesson","text":""},{"location":"Sample-Curriculum/05-Agentic-RAG/04/","title":"04 | Lesson","text":""},{"location":"Sample-Curriculum/05-Agentic-RAG/05/","title":"05 | Lesson","text":""},{"location":"Sample-Curriculum/05-Agentic-RAG/06/","title":"06 | Exercise","text":""},{"location":"Sample-Curriculum/05-Agentic-RAG/07/","title":"07 | Summary","text":""},{"location":"Sample-Curriculum/06-Trustworthy-Agents/01/","title":"01 | Introduction","text":"<p>Learning Objectives</p> <p>In this lesson, we'll answer the following questions:</p> <ul> <li>How do I observe and control the actions taken by the AI Agents? </li> <li>How do I evaluate the performance of my AI Agent? </li> <li>How do I ensure my agents are responsible and trustworthy, especially when handling sensitive information?</li> <li>How do I ground my agent\u2019s responses in the most current and authoritative internal data?</li> <li>How do I ensure compliance with industry-specific regulations (e.g., GDPR, HIPAA) in my agent workflows?</li> </ul>"},{"location":"Sample-Curriculum/06-Trustworthy-Agents/01/#pre-requsites","title":"Pre-Requsites","text":""},{"location":"Sample-Curriculum/06-Trustworthy-Agents/01/#learning-resources","title":"Learning Resources","text":""},{"location":"Sample-Curriculum/06-Trustworthy-Agents/02/","title":"02 | Lesson","text":""},{"location":"Sample-Curriculum/06-Trustworthy-Agents/03/","title":"03 | Lesson","text":""},{"location":"Sample-Curriculum/06-Trustworthy-Agents/04/","title":"04 | Lesson","text":""},{"location":"Sample-Curriculum/06-Trustworthy-Agents/05/","title":"05 | Lesson","text":""},{"location":"Sample-Curriculum/06-Trustworthy-Agents/06/","title":"06 | Exercise","text":""},{"location":"Sample-Curriculum/06-Trustworthy-Agents/07/","title":"07 | Summary","text":""},{"location":"Sample-Curriculum/07-Planning-Pattern/01/","title":"01 | Introduction","text":"<p>Learning Objectives</p> <p>In this lesson, we'll answer the following questions:</p> <ul> <li>What is the overall goal of the task?<ul> <li>Understanding the end goal helps in breaking down the task into manageable subtasks.</li> </ul> </li> <li>How can the task be decomposed into smaller, manageable subtasks?<ul> <li>Identifying the subtasks is crucial for planning the sequence of actions. -What tools or resources are needed to complete each subtask?</li> <li>Knowing the required tools helps in planning their invocation and integration.</li> </ul> </li> <li>How will the agent decide the sequence of steps?<ul> <li>Determining the decision-making process ensures the agent can dynamically adjust its actions.</li> </ul> </li> <li>What criteria will be used to evaluate the success of each subtask?<ul> <li>Setting evaluation criteria helps in assessing the quality and completeness of each step.</li> </ul> </li> <li>How will the agent handle unexpected situations or errors?<ul> <li>Planning for contingencies ensures robustness and reliability.</li> </ul> </li> <li>What are the performance and efficiency considerations?<ul> <li>Ensuring the process is efficient and meets performance requirements is essential for practical applications.</li> </ul> </li> <li>How will the agent iterate and improve its output?<ul> <li>Incorporating iterative improvement mechanisms can enhance the quality of the final result.</li> </ul> </li> <li>What are the potential ethical and safety implications?<ul> <li>Considering ethical and safety aspects ensures responsible and safe deployment of the AI agent.</li> </ul> </li> </ul>"},{"location":"Sample-Curriculum/07-Planning-Pattern/01/#pre-requsites","title":"Pre-Requsites","text":""},{"location":"Sample-Curriculum/07-Planning-Pattern/01/#learning-resources","title":"Learning Resources","text":""},{"location":"Sample-Curriculum/07-Planning-Pattern/02/","title":"02 | Lesson","text":""},{"location":"Sample-Curriculum/07-Planning-Pattern/03/","title":"03 | Lesson","text":""},{"location":"Sample-Curriculum/07-Planning-Pattern/04/","title":"04 | Lesson","text":""},{"location":"Sample-Curriculum/07-Planning-Pattern/05/","title":"05 | Lesson","text":""},{"location":"Sample-Curriculum/07-Planning-Pattern/06/","title":"06 | Exercise","text":""},{"location":"Sample-Curriculum/07-Planning-Pattern/07/","title":"07 | Summary","text":""},{"location":"Sample-Curriculum/08-MultiAgent-Pattern/01/","title":"01 | Introduction","text":"<p>Learning Objectives</p> <p>In this lesson, we'll answer the following questions:</p> <ul> <li>What are the scenarios where multi-agents are applicable to? </li> <li>What are the advantages of using multi-agents over just one singular agent doing multiple tasks? </li> <li>What are the building blocks of implementing the multi-agent design pattern? </li> <li>How do we have visibility to how the multiple agents are interacting with each other? </li> </ul>"},{"location":"Sample-Curriculum/08-MultiAgent-Pattern/01/#pre-requsites","title":"Pre-Requsites","text":""},{"location":"Sample-Curriculum/08-MultiAgent-Pattern/01/#learning-resources","title":"Learning Resources","text":""},{"location":"Sample-Curriculum/08-MultiAgent-Pattern/02/","title":"02 | Lesson","text":""},{"location":"Sample-Curriculum/08-MultiAgent-Pattern/03/","title":"03 | Lesson","text":""},{"location":"Sample-Curriculum/08-MultiAgent-Pattern/04/","title":"04 | Lesson","text":""},{"location":"Sample-Curriculum/08-MultiAgent-Pattern/05/","title":"05 | Lesson","text":""},{"location":"Sample-Curriculum/08-MultiAgent-Pattern/06/","title":"06 | Exercise","text":""},{"location":"Sample-Curriculum/08-MultiAgent-Pattern/07/","title":"07 | Summary","text":""},{"location":"Sample-Curriculum/09-MetaCognition-Pattern/01/","title":"01 | Introduction","text":"<p>Learning Objectives</p> <p>In this lesson, we'll answer the following questions:</p> <ul> <li>TBD</li> <li>TBD</li> <li>TBD</li> <li>TBD</li> </ul>"},{"location":"Sample-Curriculum/09-MetaCognition-Pattern/01/#pre-requsites","title":"Pre-Requsites","text":""},{"location":"Sample-Curriculum/09-MetaCognition-Pattern/01/#learning-resources","title":"Learning Resources","text":""},{"location":"Sample-Curriculum/09-MetaCognition-Pattern/02/","title":"02 | Lesson","text":""},{"location":"Sample-Curriculum/09-MetaCognition-Pattern/03/","title":"03 | Lesson","text":""},{"location":"Sample-Curriculum/09-MetaCognition-Pattern/04/","title":"04 | Lesson","text":""},{"location":"Sample-Curriculum/09-MetaCognition-Pattern/05/","title":"05 | Lesson","text":""},{"location":"Sample-Curriculum/09-MetaCognition-Pattern/06/","title":"06 | Exercise","text":""},{"location":"Sample-Curriculum/09-MetaCognition-Pattern/07/","title":"07 | Summary","text":""},{"location":"Sample-Curriculum/10-Agents-In-Production/01/","title":"01 | Introduction","text":"<p>Learning Objectives</p> <p>In this lesson, we'll answer the following questions:</p> <ul> <li>What\u2019s the best way to manage complex multi-turn dialogs at scale?</li> <li>How does AI Agent solutions integrate with other Azure Services? </li> <li>How do I measure the success of my agentic solutions over time and demonstrate ROI?</li> <li>What skill sets do I need on my team to build and maintain AI agents effectively?</li> <li>How do I manage costs and ensure the solution scales responsibly as usage grows?</li> <li>How will the rapidly evolving AI ecosystem affect my agent solutions over time, and how can I remain agile?</li> </ul>"},{"location":"Sample-Curriculum/10-Agents-In-Production/01/#pre-requsites","title":"Pre-Requsites","text":""},{"location":"Sample-Curriculum/10-Agents-In-Production/01/#learning-resources","title":"Learning Resources","text":""},{"location":"Sample-Curriculum/10-Agents-In-Production/02/","title":"02 | Lesson","text":""},{"location":"Sample-Curriculum/10-Agents-In-Production/03/","title":"03 | Lesson","text":""},{"location":"Sample-Curriculum/10-Agents-In-Production/04/","title":"04 | Lesson","text":""},{"location":"Sample-Curriculum/10-Agents-In-Production/05/","title":"05 | Lesson","text":""},{"location":"Sample-Curriculum/10-Agents-In-Production/06/","title":"06 | Exercise","text":""},{"location":"Sample-Curriculum/10-Agents-In-Production/07/","title":"07 | Summary","text":""},{"location":"Sample-Workshop/1-Overview/00/","title":"1.1 Learning Objectives","text":"<p>This is based on the Build a custom chat app with the Azure AI Foundry SDK tutorial but adapted for use in workshops with a devcontainer for fast setup. Fork the repo, launch GitHub Codespaces - and get started!</p> <p>The lab teaches you to build a RAG-based copilot using the Azure AI Foundry platform By completing this lab, you will learn to do the following tasks:</p> <ol> <li>Use the Azure AI Foundry Portal to<ul> <li>start a new Azure AI project</li> <li>discover and deploy AI models to the project</li> <li>add an Azure AI Search resource to the project</li> <li>setup an Application Insights resource for tracing</li> </ul> </li> <li>Use the Azure AI Foundry SDK to<ul> <li>create a new search index with your data</li> <li>extract customer intent with an intent mapping prompt template</li> <li>retrieve relevant knowledge using the search index</li> <li>create a chat agent with a grounded prompt template</li> <li>process customer queries returning responses grounded in my data.</li> </ul> </li> <li>Use the Azure AI Evaluation SDK to assess app quality by<ul> <li>creating a custom evaluation dataset.</li> <li>executing a custom evaluation workflow.</li> <li>viewing evaluation results, in your local environment.</li> <li>viewing evaluation results, in Azure AI Foundry portal.</li> </ul> </li> </ol> <p>This sets you up with a \"sandbox\" project that you can use to explore other features or tooling in Azure AI Foundry. For example - try bringing your own application data, or adding secondary data sources for knowledge retrieval as part of the RAG flow.</p> BONUS: Use what you learn here to explore Contoso Chat next! (click to expand) <p>Contoso Chat is an open-source reference sample that implements the retail RAG-based copilot (using the same data) in a code-first approach from initial provisioning to final production deployment. </p> <ul> <li>The current version (v3) provisions the Azure AI Foundry resources using the Azure Developer CLI (<code>azd provision</code>) and deploys the final application to Azure Container Apps for a hosted API endpoint.</li> <li>The next version (v4) will incorporate more elements from the Azure AI Foundry SDKs that we highlight in this RAG tutorial, including use of the Azure AI Model Inference API and the Azure AI Evaluation SDK.</li> </ul>"},{"location":"Sample-Workshop/1-Overview/01/","title":"1.2 Application Scenario","text":"<p>In this tutorial, we build a retail chat AI (copilot) that uses Retrieval Augmented Generation (RAG) to ground the chat responses in the retailer's own data. Let's briefly review what this means.</p>"},{"location":"Sample-Workshop/1-Overview/01/#1-rag-chat-app-tutorial","title":"1. RAG Chat App (tutorial)","text":"<p>This RAG Chat tutorial provides a quickstart for building and evaluating a basic RAG-based copilot using the Azure AI Foundry portal and SDK. The tutorial is grounded in the Contoso Outdoors retailer data and combines both low-code (Portal) and code-first (SDK) steps to teach the latest Azure AI Foundry tools and features. Think of this as a sandbox for open exploration</p> <p>The figure explains the RAG pattern visually:</p> <ol> <li>The user question (prompt) is received at the copilot hosted endpoint</li> <li>The question is used to retrieve related knowledge from relevant sources.</li> <li>The prompt is then augmented with knowledge as context, and sent to the model.</li> <li>The model now generates a response that is \"grounded\" in this knowledge context.</li> </ol> <p></p>"},{"location":"Sample-Workshop/1-Overview/01/#2-contoso-outdoor-chat-ui","title":"2. Contoso Outdoor (chat UI)","text":"<p>Contoso Outdoor is a fictitious enterprise retailer specializing in hiking and camping gear for outdoor enthusiasts. Their website (chat UI) provides customers with a catalog of their products, with product pages offering detailed information for user review. We'll look at the retailer data sources in the next section.</p> <p></p>"},{"location":"Sample-Workshop/1-Overview/01/#3-contoso-chat-chat-ai","title":"3. Contoso Chat (chat AI)","text":"<p>The chat UI shown is not used in THIS workshop - but code is open-source if useful.</p> <p>Contoso Chat is the open-source reference implementation of a custom RAG-based retail copilot based on the Contoso Outdoor retail scenario. It is implemented as an AI App Template that can be provisioned and deployed to Azure Container Apps to provide a hosted API endpoint. Customer requests on the chat UI (website) are now directed to this chat AI (endpoint) for processing, allowing for the user experience shown below.</p> <p></p>"},{"location":"Sample-Workshop/1-Overview/02/","title":"1.3 Application Data","text":"<p>The Retrieval Augmented Generation (RAG) design pattern allows us to customize the AI by enhancing the user prompt with dynamically retrieved knowledge that grounds the responses in the provided context. Let's understand the shape of the data available to us - and think proactively about how you could bring your data into this mix.</p>"},{"location":"Sample-Workshop/1-Overview/02/#1-customer-info","title":"1. Customer Info","text":"<p>This record represents a single customer, providing their profile information (\"id\", name, contact info) and their purchase history (\"orders\"). This JSON data may be stored in a noSQL datbase like Azure CosmosDB and retrieved dynamically by the chat AI.</p> SAMPLE DATA (JSON) - click to expand <pre><code>{\n    \"id\": \"1\",\n    \"firstName\": \"John\",\n    \"lastName\": \"Smith\",\n    \"age\": 35,\n    \"email\": \"johnsmith@example.com\",\n    \"phone\": \"555-123-4567\",\n    \"address\": \"123 Main St,  Anytown USA, 12345\",\n    \"membership\": \"Base\",\n\n    \"orders\": [\n    {\n        \"id\": 29,\n        \"productId\": 8,\n        \"quantity\": 2,\n        \"total\": 700.0,\n        \"date\": \"2/10/2023\",\n        \"name\": \"Alpine Explorer Tent\",\n        \"unitprice\": 350.0,\n        \"category\": \"Tents\",\n        \"brand\": \"AlpineGear\",\n        \"description\": \"Welcome to the joy of camping with the Alpine Explorer Tent! This robust, 8-person, 3-season marvel is from the responsible hands of the AlpineGear brand. Promising an enviable setup that is as straightforward as counting sheep, your camping experience is transformed into a breezy pastime. Looking for privacy? The detachable divider provides separate spaces at a moment's notice. Love a tent that breathes? The numerous mesh windows and adjustable vents fend off any condensation dragon trying to dampen your adventure fun. The waterproof assurance keeps you worry-free during unexpected rain dances. With a built-in gear loft to stash away your outdoor essentials, the Alpine Explorer Tent emerges as a smooth balance of privacy, comfort, and convenience. Simply put, this tent isn't just a shelter - it's your second home in the heart of nature! Whether you're a seasoned camper or a nature-loving novice, this tent makes exploring the outdoors a joyous journey.\"\n    },\n    {\n        \"id\": 1,\n        \"productId\": 1,\n        \"quantity\": 2,\n        \"total\": 500.0,\n        \"date\": \"1/5/2023\",\n        \"name\": \"TrailMaster X4 Tent\",\n        \"unitprice\": 250.0,\n        \"category\": \"Tents\",\n        \"brand\": \"OutdoorLiving\",\n        \"description\": \"Unveiling the TrailMaster X4 Tent from OutdoorLiving, your home away from home for your next camping adventure. Crafted from durable polyester, this tent boasts a spacious interior perfect for four occupants. It ensures your dryness under drizzly skies thanks to its water-resistant construction, and the accompanying rainfly adds an extra layer of weather protection. It offers refreshing airflow and bug defence, courtesy of its mesh panels. Accessibility is not an issue with its multiple doors and interior pockets that keep small items tidy. Reflective guy lines grant better visibility at night, and the freestanding design simplifies setup and relocation. With the included carry bag, transporting this convenient abode becomes a breeze. Be it an overnight getaway or a week-long nature escapade, the TrailMaster X4 Tent provides comfort, convenience, and concord with the great outdoors. Comes with a two-year limited warranty to ensure customer satisfaction.\"\n    },\n    {\n        \"id\": 19,\n        \"productId\": 5,\n        \"quantity\": 1,\n        \"total\": 60.0,\n        \"date\": \"1/25/2023\",\n        \"name\": \"BaseCamp Folding Table\",\n        \"unitprice\": 60.0,\n        \"category\": \"Camping Tables\",\n        \"brand\": \"CampBuddy\",\n        \"description\": \"CampBuddy's BaseCamp Folding Table is an adventurer's best friend. Lightweight yet powerful, the table is a testament to fun-meets-function and will elevate any outing to new heights. Crafted from resilient, rust-resistant aluminum, the table boasts a generously sized 48 x 24 inches tabletop, perfect for meal times, games and more. The foldable design is a godsend for on-the-go explorers. Adjustable legs rise to the occasion to conquer uneven terrains and offer height versatility, while the built-in handle simplifies transportation. Additional features like non-slip feet, integrated cup holders and mesh pockets add a pinch of finesse. Quick to set up without the need for extra tools, this table is a silent yet indispensable sidekick during camping, picnics, and other outdoor events. Don't miss out on the opportunity to take your outdoor experiences to a new level with the BaseCamp Folding Table. Get yours today and embark on new adventures tomorrow!\"\n    }]\n}\n</code></pre>"},{"location":"Sample-Workshop/1-Overview/02/#2-product-manual-info","title":"2. Product Manual Info","text":"<p>This record represents a single product in the retailer's catalog with extensive text (formatted as Markdown) covering information like brand, category, features, technical specs, user guide, cautions, warranty information, return policy, reviews, FAQ. This information may be used for building the Contoso Web UI, and potentially for grounding responses related to richer QA later. </p> <p>The product info has been rendered as a Markmap for visual clarity. Simply zoom in/out or pan in/out to explore the content. You can click on any node (circle) to expand/collapse its sub-tree. You may need to refresh or reload page to re-render the tree.</p> SAMPLE RECORD (Markdown) - click to expand # Information about product item_number: 1
TrailMaster X4 Tent, price $250,

## Brand
OutdoorLiving

## Category
Tents

## Features
- Polyester material for durability
- Spacious interior to accommodate multiple people
- Easy setup with included instructions
- Water-resistant construction to withstand light rain
- Mesh panels for ventilation and insect protection
- Rainfly included for added weather protection
- Multiple doors for convenient entry and exit
- Interior pockets for organizing small items
- Reflective guy lines for improved visibility at night
- Freestanding design for easy setup and relocation
- Carry bag included for convenient storage and transportation

## Technical Specs
**Best Use**: Camping  
**Capacity**: 4-person  
**Season Rating**: 3-season  
**Setup**: Freestanding  
**Material**: Polyester  
**Waterproof**: Yes  
**Floor Area**: 80 square feet  
**Peak Height**: 6 feet  
**Number of Doors**: 2  
**Color**: Green  
**Rainfly**: Included  
**Rainfly Waterproof Rating**: 2000mm  
**Tent Poles**: Aluminum  
**Pole Diameter**: 9mm  
**Ventilation**: Mesh panels and adjustable vents  
**Interior Pockets**: Yes (4 pockets)  
**Gear Loft**: Included  
**Footprint**: Sold separately  
**Guy Lines**: Reflective  
**Stakes**: Aluminum  
**Carry Bag**: Included  
**Dimensions**: 10ft x 8ft x 6ft (length x width x peak height)  
**Packed Size**: 24 inches x 8 inches  
**Weight**: 12 lbs  

## User Guide

### Introduction

Thank you for choosing the TrailMaster X4 Tent. This user guide provides instructions on how to set up, use, and maintain your tent effectively. Please read this guide thoroughly before using the tent.

### Package Contents

Ensure that the package includes the following components:

- TrailMaster X4 Tent body
- Tent poles
- Rainfly (if applicable)
- Stakes and guy lines
- Carry bag
- User Guide

If any components are missing or damaged, please contact our customer support immediately.

### Tent Setup

#### Step 1: Selecting a Suitable Location

- Find a level and clear area for pitching the tent.
- Remove any sharp objects or debris that could damage the tent floor.

#### Step 2: Unpacking and Organizing Components

- Lay out all the tent components on the ground.
- Familiarize yourself with each part, including the tent body, poles, rainfly, stakes, and guy lines.

#### Step 3: Assembling the Tent Poles

- Connect the tent poles according to their designated color codes or numbering.
- Slide the connected poles through the pole sleeves or attach them to the tent body clips.

#### Step 4: Setting up the Tent Body

- Begin at one end and raise the tent body by pushing up the poles.
- Ensure that the tent body is evenly stretched and centered.
- Secure the tent body to the ground using stakes and guy lines as needed.

#### Step 5: Attaching the Rainfly (if applicable)

- If your tent includes a rainfly, spread it over the tent body.
- Attach the rainfly to the tent corners and secure it with the provided buckles or clips.
- Adjust the tension of the rainfly to ensure proper airflow and weather protection.

#### Step 6: Securing the Tent

- Stake down the tent corners and guy out the guy lines for additional stability.
- Adjust the tension of the guy lines to provide optimal stability and wind resistance.

### Tent Takedown and Storage

#### Step 1: Removing Stakes and Guy Lines

- Remove all stakes from the ground.
- Untie or disconnect the guy lines from the tent and store them separately.

#### Step 2: Taking Down the Tent Body

- Start by collapsing the tent poles carefully.
- Remove the poles from the pole sleeves or clips.
- Collapse the tent body and fold it neatly.

#### Step 3: Disassembling the Tent Poles

- Disconnect and separate the individual pole sections.
- Store the poles in their designated bag or sleeve.

#### Step 4: Packing the Tent

- Fold the tent body tightly and place it in the carry bag.
- Ensure that the rainfly and any other components are also packed securely.

### Tent Care and Maintenance

- Clean the tent regularly with mild soap and water.
- Avoid using harsh chemicals or abrasive cleaners.
- Allow the tent to dry completely before storing it.
- Store the tent in a cool, dry place away from direct sunlight.

## Cautions
1. **Avoid Uneven or Rocky Surfaces**: Do not place the tent on uneven or rocky surfaces.
2. **Stay Clear of Hazardous Areas**: Avoid setting up the tent near hazardous areas.
3. **No Open Flames or Heat Sources**: Do not use open flames, candles, or any other flammable heat sources near the tent.
4. **Avoid Overloading**: Do not exceed the maximum weight capacity or overload the tent with excessive gear or equipment.
5. **Don't Leave Unattended**: Do not leave the tent unattended while open or occupied.
6. **Avoid Sharp Objects**: Keep sharp objects away from the tent to prevent damage to the fabric or punctures.
7. **Avoid Using Harsh Chemicals**: Do not use harsh chemicals or abrasive cleaners on the tent, as they may damage the material.
8. **Don't Store Wet**: Do not store the tent when it is wet or damp, as it can lead to mold, mildew, or fabric deterioration.
9. **Avoid Direct Sunlight**: Avoid prolonged exposure of the tent to direct sunlight, as it can cause fading or weakening of the fabric.
10. **Don't Neglect Maintenance**: Regularly clean and maintain the tent according to the provided instructions to ensure its longevity and performance.

## Warranty Information
Thank you for purchasing the TrailMaster X4 Tent. We are confident in the quality and durability of our product. This warranty provides coverage for any manufacturing defects or issues that may arise during normal use of the tent. Please read the terms and conditions of the warranty below:

1. **Warranty Coverage**: The TrailMaster X4 Tent is covered by a **2-year limited warranty** from the date of purchase. This warranty covers manufacturing defects in materials and workmanship.

2. **What is Covered**:
- Seam or fabric tears that occur under normal use and are not a result of misuse or abuse.
- Issues with the tent poles, zippers, buckles, or other hardware components that affect the functionality of the tent.
- Problems with the rainfly or other included accessories that impact the performance of the tent.

3. **What is Not Covered**:
- Damage caused by misuse, abuse, or improper care of the tent.
- Normal wear and tear or cosmetic damage that does not affect the functionality of the tent.
- Damage caused by extreme weather conditions, natural disasters, or acts of nature.
- Any modifications or alterations made to the tent by the user.

4. **Claim Process**:
- In the event of a warranty claim, please contact our customer support (contact details provided in the user guide) to initiate the process.
- Provide proof of purchase, including the date and place of purchase, along with a detailed description and supporting evidence of the issue.

5. **Resolution Options**:
- Upon receipt of the warranty claim, our customer support team will assess the issue and determine the appropriate resolution.
- Options may include repair, replacement of the defective parts, or, if necessary, replacement of the entire tent.

6. **Limitations and Exclusions**:
- Our warranty is non-transferable and applies only to the original purchaser of the TrailMaster X4 Tent.
- The warranty does not cover any incidental or consequential damages resulting from the use or inability to use the tent.
- Any unauthorized repairs or alterations void the warranty.

### Contact Information

If you have any questions or need further assistance, please contact our customer support:

- Customer Support Phone: +1-800-123-4567
- Customer Support Email: support@example.com

## Return Policy
- **If Membership status "None        ":**  Returns are accepted within 30 days of purchase, provided the tent is unused, undamaged and in its original packaging. Customer is responsible for the cost of return shipping. Once the returned item is received, a refund will be issued for the cost of the item minus a 10% restocking fee. If the item was damaged during shipping or if there is a defect, the customer should contact customer service within 7 days of receiving the item.
- **If Membership status "Gold":**  Returns are accepted within 60 days of purchase, provided the tent is unused, undamaged and in its original packaging. Free return shipping is provided. Once the returned item is received, a full refund will be issued. If the item was damaged during shipping or if there is a defect, the customer should contact customer service within 7 days of receiving the item.
- **If Membership status "Platinum":**  Returns are accepted within 90 days of purchase, provided the tent is unused, undamaged and in its original packaging. Free return shipping is provided, and a full refund will be issued. If the item was damaged during shipping or if there is a defect, the customer should contact customer service within 7 days of receiving the item.

## Reviews
1) **Rating:** 5
**Review:** I am extremely happy with my TrailMaster X4 Tent! It's spacious, easy to set up, and kept me dry during a storm. The UV protection is a great addition too. Highly recommend it to anyone who loves camping!

2) **Rating:** 3
**Review:** I bought the TrailMaster X4 Tent, and while it's waterproof and has a spacious interior, I found it a bit difficult to set up. It's a decent tent, but I wish it were easier to assemble.

3) **Rating:** 5
**Review:** The TrailMaster X4 Tent is a fantastic investment for any serious camper. The easy setup and spacious interior make it perfect for extended trips, and the waterproof design kept us dry in heavy rain.

4) **Rating:** 4
**Review:** I like the TrailMaster X4 Tent, but I wish it came in more colors. It's comfortable and has many useful features, but the green color just isn't my favorite. Overall, it's a good tent.

5) **Rating:** 5
**Review:** This tent is perfect for my family camping trips. The spacious interior and convenient storage pocket make it easy to stay organized. It's also super easy to set up, making it a great addition to our gear.

## FAQ
1) Can the TrailMaster X4 Tent be used in winter conditions?
The TrailMaster X4 Tent is designed for 3-season use and may not be suitable for extreme winter conditions with heavy snow and freezing temperatures.

2) How many people can comfortably sleep in the TrailMaster X4 Tent?
The TrailMaster X4 Tent can comfortably accommodate up to 4 people with room for their gear.

3) Is there a warranty on the TrailMaster X4 Tent?
Yes, the TrailMaster X4 Tent comes with a 2-year limited warranty against manufacturing defects.

4) Are there any additional accessories included with the TrailMaster X4 Tent?
The TrailMaster X4 Tent includes a rainfly, tent stakes, guy lines, and a carry bag for easy transport.

5) Can the TrailMaster X4 Tent be easily carried during hikes?
Yes, the TrailMaster X4 Tent weighs just 12lbs, and when packed in its carry bag, it can be comfortably carried during hikes."},{"location":"Sample-Workshop/1-Overview/02/#3-product-catalog-info","title":"3. Product Catalog Info","text":"<p>This record represents a single product item in the product catalog database, with a unique product ID. The <code>products.csv</code> file contains a collection of these records, representing the entire Contoso Outdoors product catalog at a high level. </p> <p>Each product ID has a corresponding \"product manual\" record that provides more extensive detail (e.g, in website pages). The product catalog entry itself contains just the {id, name, price, category, brand, description} information required for creating product indexes and searching for matching results (for later retrieval) based on a customer query. </p> <p>The catalog record below corresponds to the product manual record above.</p> SAMPLE RECORD (CSV) - click to expand <pre><code>id = 1,\nname = TrailMaster X4 Tent,\nprice = 250.0,\ncategory = Tents,\nbrand = OutdoorLiving,\ndescription = \"Unveiling the TrailMaster X4 Tent from \\\n    OutdoorLiving, your home away from home for your next \\\n    camping adventure. Crafted from durable polyester, \\\n    this tent boasts a spacious interior perfect for four \\\n    occupants. It ensures your dryness under drizzly skies \\\n    thanks to its water-resistant construction, and the \\\n    accompanying rainfly adds an extra layer of weather \\\n    protection. It offers refreshing airflow and bug defence, \\\n    courtesy of its mesh panels. Accessibility is not an issue \\\n    with its multiple doors and interior pockets that keep \\\n    small items tidy. Reflective guy lines grant better \\\n    visibility at night, and the freestanding design \\\n    simplifies setup and relocation. With the included \\\n    carry bag, transporting this convenient abode becomes \\\n    a breeze. Be it an overnight getaway or a week-long nature \\\n    escapade, the TrailMaster X4 Tent provides comfort, \\\n    convenience, and concord with the great outdoors. Comes with \\\n    a two-year limited warranty to ensure customer satisfaction.\"\n</code></pre>"},{"location":"Sample-Workshop/1-Overview/03/","title":"1.4 RAG Chat Tutorial","text":"<p>This markmap provides the big picture for navigating this RAG Chat tutorial. Learn to build a minimal RAG-based copilot experience using Azure AI Foundry Portal (for setup) and Azure AI Foundry SDK (for ideation and evaluation).</p> <p>RAG Chat Roadmap: Refresh this page to see markmap if needed</p> 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"},{"location":"Sample-Workshop/2-Setup/01/","title":"2.1 Create AI Project","text":"<p>This is Part 1 of the tutorial. This stage is completed USING THE AZURE AI FOUNDRY PORTAL</p> <p>At the end of this section, you should have provisioned an Azure AI Hub and Azure AI project resource, setup an Azure AI Search resource and deployed two Azure OpenAI models for implementing the RAG-based copilot. You should also have launched GitHub Codespaces and configured your development environment to work with your provisioned Azure infrastructure.</p>"},{"location":"Sample-Workshop/2-Setup/01/#1-log-into-azure-ai-foundry","title":"1. Log Into Azure AI Foundry","text":"<ol> <li>Open a private browser and navigate to https://ai.azure.com.</li> <li>Log in with an active Azure subscription. Note the tenant ID if multi-tenant.</li> <li>You should see a landing page with a blue \"+ Create project\" button as shown below.      </li> </ol> <p>Note: If you had previously created projects, those will be listed as shown above. Don't worry if you don't see any listed for your profile. We are going to create a new project next.</p>"},{"location":"Sample-Workshop/2-Setup/01/#2-create-a-new-project","title":"2. Create a new project","text":"<ol> <li> <p>Click the \"+ Create project\" button. You should see a dialog popup like this. Your default project name and hub information will be different and reflect your prior activity.     </p> </li> <li> <p>Change the default project name to something memorable - I used <code>ninarasi-ragchat-v1</code>.</p> </li> <li>We also want to create a new hub for our new AI project - let's fix that next in the dialog.</li> </ol> TROUBLESHOOTING: Your Create a project dialog looks different. (Click to expand) <p>You may see a dialog like this instead. This is typically the case when you don't have a pre-existing Hub selection and the workflow now automatically adds a default Hub resource. In this case, customize the project name as specified in step 1 above, then skip the step 3 below and go directly to customize the hub name as described in step 4 to complete the dialog.</p> <p></p>"},{"location":"Sample-Workshop/2-Setup/01/#3-create-new-hub","title":"3. Create new hub","text":"<ol> <li>Click the <code>Create new hub</code> (blue lettering) in dialog above.</li> <li>Pick a memorable name that reflects the project - I used <code>ninarasi-ragchat-hub</code> </li> <li>Click \"Next\". It returns you to the previous dialog, with an enhanced view as shown     </li> </ol>"},{"location":"Sample-Workshop/2-Setup/01/#4-customize-the-hub","title":"4. Customize the hub","text":"<ol> <li>Click the \"Customize\" button in that dialog. This lets you customize the defaults as shown.</li> <li>First, select a relevant Location with relevant model quota - I used <code>East US2</code> </li> <li>Next,customize the resource group name to be memorable - I used <code>ninarasi-ragchat-rg</code> </li> <li>Next, click \"Create new AI Search\" (blue lettering) in the dialog to trigger a new pop-up</li> </ol>"},{"location":"Sample-Workshop/2-Setup/01/#5-create-new-ai-search","title":"5. Create new AI Search","text":"<ol> <li>Customize resource name - I used <code>ninarasi-ragchat-aisearch</code> - then hit Next.     </li> <li>You return to the Create a project wizard - hit Next to get to review.     </li> <li>Review the details one last time - hit Create to confirm AI project creation.     </li> <li>Creation takes a few minutes - all elements will show green on success.     </li> </ol>"},{"location":"Sample-Workshop/2-Setup/01/#6-review-created-ai-project","title":"6. Review Created AI Project","text":"<ol> <li>You should automatically be taken to the AI Project overview page as shown. Note the Project connection string under <code>Project details</code> - we'll revisit it later.     </li> <li>Click on the Open in management center link (highlighted in red) - it takes you to this Management Center view. Clicking <code>Go to project</code> will take you back to the AI project.     </li> <li>However, for now click on the Connected Resources option in the sidebar. This lets us see which resources can be accessed via the Project connection we noted earlier. Verify that Azure AI Search is one of the listed resources.     </li> </ol> <p>CONGRATULATIONS! You created your Azure AI Hub &amp; Project resources</p>"},{"location":"Sample-Workshop/2-Setup/02/","title":"2.2 Deploy AI Models","text":"<p>Let's revisit our Retrieval Augmented Generation design pattern. Note that we make use of two models to implement this design architecture.</p> <ol> <li>A Large Language Model (Embedding) for vectorizing the user query.</li> <li>A Large Language Model (Chat) for generating the response returned to user.</li> </ol> <p></p> <p>Let's find the right models to use and deploy them to our Azure AI project so we can use them in our RAG-based copilot implementation. Start by navigating to the Azure AI Project overview page. Then select the Models + endpoints link under My assets.</p> <p></p>"},{"location":"Sample-Workshop/2-Setup/02/#1-deploy-chat-model","title":"1. Deploy Chat Model","text":""},{"location":"Sample-Workshop/2-Setup/02/#11-select-a-chat-model","title":"1.1. Select A Chat Model","text":"<ol> <li> <p>Click the blue \"Deploy model\" button and pick Deploy base model from the dropdown options.</p> <p></p> </li> <li> <p>If you know the specific model to use, you can search for it here. In our case, let's look at what our options are. First, click the Collections filter and select Azure OpenAI. Next, click the Inference tasks filter and select Chat completion. We can see that this reduces our choices from 1800+ models in the Azure AI model catalog to 9 matching models.</p> <p></p> </li> </ol>"},{"location":"Sample-Workshop/2-Setup/02/#12-deploy-the-chat-model","title":"1.2. Deploy the Chat Model","text":"<ol> <li>We can pick any of those options as shown above, to see a Model Card with more details. Let's pick <code>gpt-4o-mini</code> and click Confirm to get this deployment wizard. Note that it selects a Global Standard deployment type by default. The deployment has a default capacity of 10K tokens per minute (TPM) which can be useful when we begin the evaluation phase.</li> </ol> <ol> <li>Click on the dropdown to see other Deployment type options. Read the documentation to learn more about what each provides. Global Standard is the recommended starting place for customers so let's go with that.</li> </ol>"},{"location":"Sample-Workshop/2-Setup/02/#13-verify-deployment","title":"1.3. Verify Deployment","text":"<p>On successful deployment, you will be taken to the model deployment page where you can review the details and retrieve relevant information like the Endpoint and Key information, for use with code-first clients.</p> <p></p> <p>You can Open in playground and use the Azure AI Portal as an ideation tool to explore different prompt templates, model configurations and multi-turn conversational approaches to determine if this model is in fact suitable for your app scenario.</p> <p>Task: Ask the model to <code>Tell me about hiking boots for my trip to Spain</code> - is response grounded?</p> <p></p> <p>Homework: Complete the Deploy an enterprise chat app tutorial with your data. Is response grounded now?</p>"},{"location":"Sample-Workshop/2-Setup/02/#14-view-metrics","title":"1.4. View Metrics","text":"<p>You can also select the Metrics tab of deployed models within an Azure AI project to get metrics about the cost (tokens) and performance (requests) of that model in a given time frame. The screenshot shows the data taken for this model after completing the entire project. The spike reflects the requests made during the evaluation stage of the workflow.</p> <p></p> <p>You can also click the Open in Azure Monitor link to open up the Azure Monitor dashboard in the Azure Portal as shown below, allowing you to drill down into various metrics or establish dashboards to monitor trends of interest.</p> <p></p>"},{"location":"Sample-Workshop/2-Setup/02/#2-deploy-embedding-model","title":"2. Deploy Embedding Model","text":"<p>The previous steps focused on the chat completion model which has many choices for us to select from. Now, let's look at embeddings. </p>"},{"location":"Sample-Workshop/2-Setup/02/#21-select-deploy-model","title":"2.1. Select &amp; Deploy Model","text":"<p>Start by setting the Inference Task to Embeddings. </p> <p>You'll find there are only about 11 models that match this filter - setting the Collection to Azure OpenAI reduces this further to 5. As before, let's select a model and review the card to see if it matches our needs. </p> <p>Then Confirm to get the Deployment wizard dialog.</p> <p></p> <p>And Deploy to complete the workflow.</p> <p></p>"},{"location":"Sample-Workshop/2-Setup/02/#23-verify-deployment","title":"2.3. Verify Deployment","text":"<p>Similarly, we can use the deployment card to view deployment details and explore metrics. But note that we don't have a Playground for embeddings.</p> <p></p>"},{"location":"Sample-Workshop/2-Setup/02/#3-deployment-complete","title":"3. Deployment Complete","text":"<p>The Azure AI Project overview page will now list both models under the <code>Models + endpoints</code> tab for easy lookup later (if you want to explore metrics or engage in Playground).</p> <p></p> <p>CONGRATULATIONS! You deployed both the AI models needed for RAG</p>"},{"location":"Sample-Workshop/2-Setup/03/","title":"2.3 Add Azure AI Search","text":"<p>The official tutorial recommends setting up an Azure AI Search resource at this stage. This was done under the assumption that the default Azure AI project setup did not create (new) or reuse (existing) Azure AI Search resources. </p> <p>However, since we opted to add Azure AI Search during project setup, we have nothing further to do at this stage! Note that the search resource is not yet populated with our data (search indexes). We'll get there in the Ideate section.</p> <p>CONGRATULATIONS! You completed setup of Azure AI Search indexes for your data</p>"},{"location":"Sample-Workshop/2-Setup/04/","title":"2.4 Add App Insights","text":""},{"location":"Sample-Workshop/2-Setup/04/#tracing-observability","title":"Tracing &amp; Observability","text":"<p>While not covered explicitly in the tutorial, we will be working with code in the Ideate section that is instrumented for observability (tracing). </p> <ul> <li>See: How to Trace your application with Azure AI Inference SDK</li> </ul> <p>In order to visualize those traces in the Azure AI Foundry Portal, we need to attach an Application Insights resource to our Azure AI project ahead of time. </p> <ul> <li>See: View your traces in Azure AI Foundry Portal</li> </ul>"},{"location":"Sample-Workshop/2-Setup/04/#create-new-app-insights","title":"Create New App Insights","text":"<p>Let's follow those steps (as illustrated in the animated gif below):</p> <ol> <li>Navigate to your Azure AI Project resource in the Azure AI Foundry portal</li> <li>Select the Tracing option in the menu sidebar </li> <li>Select Create New to attach a new Application Insights resource to the project</li> <li>Provide a name and select Create.</li> </ol> <p></p> <p>CONGRATULATIONS! You activated App Insights for tracing your Azure AI project</p>"},{"location":"Sample-Workshop/2-Setup/05/","title":"2.5 Setup Local Environment","text":"<p>The previous steps completed the setup of our Azure AI infrastructure (resources). Now it's time to setup our development environment to talk to our Azure backend.</p>"},{"location":"Sample-Workshop/2-Setup/05/#1-launch-github-codespaces","title":"1. Launch GitHub Codespaces","text":"<p>If you had not previously done so, complete the Getting Started steps now.</p> <ol> <li>Fork this repository to your personal GitHub profile.</li> <li>Open the fork in a new browser tab.</li> <li>Click on the blue \"Code\" button and select <code>Codespaces</code> </li> <li>Click on the <code>Create Codespaces on Main</code> button</li> </ol> <p>You should see GitHub Codespaces launch in a new browser tab. </p> <ul> <li>It will take a few minutes to complete loading. </li> <li>You should see a Visual Studio Code IDE in the browser</li> <li>When ready, you should see a VS Code terminal with active prompt.</li> </ul>"},{"location":"Sample-Workshop/2-Setup/05/#2-verify-azure-cli-installed","title":"2. Verify Azure CLI Installed","text":"<p>The repository is configured with a devcontainer that has all necessary dependencies pre-installed. Let's verify the <code>az</code> (Azure Developer CLI) was installed.</p> <pre><code>az version\n</code></pre>"},{"location":"Sample-Workshop/2-Setup/05/#3-authenticate-with-azure-cli","title":"3. Authenticate with Azure CLI","text":"<p>Log into your Azure subscription from the VS Code terminal in GitHub Codespaces using the following command, and follow the prompts to complete the workflow.</p> <pre><code>az login --use-device-code\n</code></pre> <p>If you have a multi-tenancy account, you can set the default tenant when logging in as follows, where <code>&lt;TENANTID&gt;</code> is replaced with the relevant identifier.</p> <pre><code>az login --use-device-code --tenant &lt;TENANTID&gt;\n</code></pre>"},{"location":"Sample-Workshop/2-Setup/05/#4-verify-python-packages","title":"4. Verify Python Packages","text":"<p>The codebase is set up with a <code>requirements.txt</code> file that has all the necesary Python package dependencies listed. These are auto-installed into the devcontainer at launch. Use <code>pip list | grep &lt;KEYWORD&gt;</code> to verify if specific packages were installed.</p> <p>For instance use this command to list <code>azure</code> packages installed and verify they match the ones listed in requirements (e.g., look for <code>azure-ai-projects</code>, <code>azure-ai-inference</code>, <code>azure-ai-identity</code>, <code>azure-search-documents</code>, <code>azure-core</code>, <code>azure-ai-evaluation</code>)</p> <pre><code>pip list | grep azure\n</code></pre>"},{"location":"Sample-Workshop/2-Setup/06/","title":"2.6 Setup Project Structure","text":"<p>This repository contains the following structure to start with. The <code>*.sample</code> folders or files are there for reference only, so you can check your work.</p> <pre><code>data/            # Contains application data (initial)\ndocs/            # Contains docs and guides (content)\nsrc.sample/      # Sample src/ folder\n.env.sample       # Sample .env file\n</code></pre>"},{"location":"Sample-Workshop/2-Setup/06/#1-define-src-folder-for-code","title":"1. Define <code>src/</code> folder for code","text":"<p>In this workshop, start by creating a new <code>src/</code> folder and populating it from scratch to get a sense for the development workflow. Start by creating this folder structure:</p> <pre><code>mkdir src/ src/api src/api/assets\n</code></pre> <p>Your directory structure should now look like this:</p> <pre><code>data/\ndocs/\nsrc.sample/\n.env.sample\nsrc/\nsrc/api\nsrc/api/assets\n</code></pre>"},{"location":"Sample-Workshop/2-Setup/06/#2-add-srcconfigpy-helper-script","title":"2. Add <code>src/config.py</code> helper script","text":"<p>For convenience, let's copy this from the sample location - then review the code to see what it does. Use this command at the root of the repo:</p> <pre><code>cp src.sample/api/config.py src/api/.\n</code></pre> <p>Expand the code below to get a sense of what this helper does.</p> <ol> <li>Sets the <code>ASSET_PATH</code> to the <code>assets/</code> folder in the same directory.</li> <li>Configures the app logger and enables telemetry logging (traces) for app.</li> </ol> Click to expand and view the helper script src/api/config.py<pre><code># ruff: noqa: ANN201, ANN001\nimport os\nimport sys\nimport pathlib\nimport logging\nfrom azure.identity import DefaultAzureCredential\nfrom azure.ai.projects import AIProjectClient\nfrom azure.ai.inference.tracing import AIInferenceInstrumentor\n\n# load environment variables from the .env file\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Set \"./assets\" as the path where assets are stored, resolving the absolute path:\nASSET_PATH = pathlib.Path(__file__).parent.resolve() / \"assets\"\n\n# Configure an root app logger that prints info level logs to stdout\nlogger = logging.getLogger(\"app\")\nlogger.setLevel(logging.INFO)\nlogger.addHandler(logging.StreamHandler(stream=sys.stdout))\n\n\n# Returns a module-specific logger, inheriting from the root app logger\ndef get_logger(module_name):\n    return logging.getLogger(f\"app.{module_name}\")\n\n\n# Enable instrumentation and logging of telemetry to the project\ndef enable_telemetry(log_to_project: bool = False):\n    AIInferenceInstrumentor().instrument()\n\n    # enable logging message contents\n    os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"\n\n    if log_to_project:\n        from azure.monitor.opentelemetry import configure_azure_monitor\n\n        project = AIProjectClient.from_connection_string(\n            conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"], credential=DefaultAzureCredential()\n        )\n        tracing_link = f\"https://ai.azure.com/tracing?wsid=/subscriptions/{project.scope['subscription_id']}/resourceGroups/{project.scope['resource_group_name']}/providers/Microsoft.MachineLearningServices/workspaces/{project.scope['project_name']}\"\n        application_insights_connection_string = project.telemetry.get_connection_string()\n        if not application_insights_connection_string:\n            logger.warning(\n                \"No application insights configured, telemetry will not be logged to project. Add application insights at:\"\n            )\n            logger.warning(tracing_link)\n\n            return\n\n        configure_azure_monitor(connection_string=application_insights_connection_string)\n        logger.info(\"Enabled telemetry logging to project, view traces at:\")\n        logger.info(tracing_link)\n</code></pre> <p>CONGRATULATIONS! Your development environment is ready to use.</p>"},{"location":"Sample-Workshop/2-Setup/07/","title":"2.7 Configure Env Variables","text":"<p>We are now ready to start coding the chat AI application in our local development environment. But to do this, we need to configure a few environment variables.</p>"},{"location":"Sample-Workshop/2-Setup/07/#1-create-env-file","title":"1. Create <code>.env</code> file","text":"<ol> <li>Start by copying the <code>.env.sample</code> file to <code>.env</code></li> </ol> <pre><code>cp .env.sample .env\n</code></pre> <ol> <li>Let's review what this contains</li> </ol> <pre><code>cat .env\n</code></pre> <p>You will see something like this:</p> <pre><code>AIPROJECT_CONNECTION_STRING=&lt;your-connection-string&gt;\nAISEARCH_INDEX_NAME=\"contoso-products\"\nEMBEDDINGS_MODEL=\"text-embedding-ada-002\"\nINTENT_MAPPING_MODEL=\"gpt-4o-mini\"\nCHAT_MODEL=\"gpt-4o-mini\"\nEVALUATION_MODEL=\"gpt-4o-mini\"\n</code></pre>"},{"location":"Sample-Workshop/2-Setup/07/#2-update-connection-string","title":"2. Update Connection String","text":"<p>Note that defaults are provided for everything except the <code>AIPROJECT_CONNECTION_STRING</code> - let's fix that now!</p> <ol> <li> <p>Open the Azure AI Project overview page. It should look like this:</p> <p></p> </li> <li> <p>Look for the Project connection string under the Project details tab. </p> </li> <li>Copy that into <code>.env</code> as the AIPROJECT_CONNECTION_STRING value.</li> <li>Save the changes to <code>.env</code></li> </ol>"},{"location":"Sample-Workshop/2-Setup/07/#3-review-environment-variables","title":"3. Review Environment Variables","text":"<p>Let's review our environment variables:</p> <ol> <li><code>AIPROJECT_CONNECTION_STRING</code> - is a single connection URI that allows access to all the Connected Resources in the Azure AI project (including Azure AI Search).</li> <li><code>AISEARCH_INDEX_NAME</code> - is set to <code>contoso-products</code> and represents the index name that we will create and populate with product catalog data.</li> <li><code>EMBEDDINGS_MODEL</code> - the deployed model we'll use for vectorizing queries (see: Ideate 3.2)</li> <li><code>INTENT_MAPPING_MODEL</code> - the deployed model we'll use for intent mapping (see: Ideate 3.4)</li> <li><code>CHAT_MODEL</code> - the deployed model we'll use for final chat response (see: Ideate 3.6)</li> <li><code>EVALUATION_MODEL</code> - the deployed model we'll use for quality evaluation (see: Evaluate 4.3)</li> </ol> <p>CONGRATULATIONS! Your local environment is configured for code!</p>"},{"location":"Sample-Workshop/3-Ideate/01/","title":"3.1 Add Application Data","text":"<p>This is Part 2 of the tutorial. This stage is completed USING THE AZURE AI FOUNDRY SDK.</p> <p>At the end of this section, you should have created an Azure AI Search index based on the retailer's product data, written and tested scripts to retrieve relevant product documents based on a user query, and implemented a chat AI that uses this knowledge as grounding context for a chat completion model. You will also get your first look at observability support with tracing.</p>"},{"location":"Sample-Workshop/3-Ideate/01/#1-add-productscsv-to-assets","title":"1. Add <code>products.csv</code> to <code>assets/</code>","text":"<p>We want to ground chat AI responses in our application data. In this case, we want to respond to customer queries about our products by grounding the responses in items found in our catalog.</p> <p>HOMEWORK: Think of other retail data sources that might be useful (and how to add them)</p> <p>Recall that the <code>src/config.py</code> script identifies the <code>assets/</code> folder as the source for all static assets. We already created the <code>src/api/assets</code> earlier.  Let's copy in the product catalog data into this folder now.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/assets/products.csv  src/api/assets/\n</code></pre> </li> </ol>"},{"location":"Sample-Workshop/3-Ideate/01/#2-inspect-productscsv-data","title":"2. Inspect <code>products.csv</code> data","text":"<p>Let's take a quick look at what this file contains in terms of product catalog data.</p> <ol> <li>We have 20 product records listed in CSV format.</li> <li>Each product has an id, name, price, category, brand, and text description</li> <li>The product description provides the most content about the product</li> <li>The product name is a unique title for that product.</li> </ol> Click to expand and view the Product Catalog data products.csv<pre><code>id,name,price,category,brand,description\n1,TrailMaster X4 Tent,250.0,Tents,OutdoorLiving,\"Unveiling the TrailMaster X4 Tent from OutdoorLiving, your home away from home for your next camping adventure. Crafted from durable polyester, this tent boasts a spacious interior perfect for four occupants. It ensures your dryness under drizzly skies thanks to its water-resistant construction, and the accompanying rainfly adds an extra layer of weather protection. It offers refreshing airflow and bug defence, courtesy of its mesh panels. Accessibility is not an issue with its multiple doors and interior pockets that keep small items tidy. Reflective guy lines grant better visibility at night, and the freestanding design simplifies setup and relocation. With the included carry bag, transporting this convenient abode becomes a breeze. Be it an overnight getaway or a week-long nature escapade, the TrailMaster X4 Tent provides comfort, convenience, and concord with the great outdoors. Comes with a two-year limited warranty to ensure customer satisfaction.\"\n2,Adventurer Pro Backpack,90.0,Backpacks,HikeMate,\"Venture into the wilderness with the HikeMate's Adventurer Pro Backpack! Uniquely designed with ergonomic comfort in mind, this backpack ensures a steadfast journey no matter the mileage. It boasts a generous 40L capacity wrapped up in durable nylon fabric ensuring its long-lasting performance on even the most rugged pursuits. It's meticulously fashioned with multiple compartments and pockets for organized storage, hydration system compatibility, and adjustable padded shoulder straps all in a lightweight construction. The added features of a sternum strap and hip belt enhance stability without compromising on comfort. The Adventurer Pro Backpack also prioritizes your safety with its reflective accents for when night falls. This buoyant beauty does more than carry your essentials; it carries the promise of a stress-free adventure!\"\n3,Summit Breeze Jacket,120.0,Hiking Clothing,MountainStyle,\"Discover the joy of hiking with MountainStyle's Summit Breeze Jacket. This lightweight jacket is your perfect companion for outdoor adventures. Sporting a trail-ready, windproof design and a water-resistant fabric, it's ready to withstand any weather. The breathable polyester material and adjustable cuffs keep you comfortable, whether you're ascending a mountain or strolling through a park. And its sleek black color adds style to function. The jacket features a full-zip front closure, adjustable hood, and secure zippered pockets. Experience the comfort of its inner lining and the convenience of its packable design. Crafted for night trekkers too, the jacket has reflective accents for enhanced visibility. Rugged yet chic, the Summit Breeze Jacket is more than a hiking essential, it's the gear that inspires you to reach new heights. Choose adventure, choose the Summit Breeze Jacket.\"\n4,TrekReady Hiking Boots,140.0,Hiking Footwear,TrekReady,\"Introducing the TrekReady Hiking Boots - stepping up your hiking game, one footprint at a time! Crafted from leather, these stylistic Trailmates are made to last. TrekReady infuses durability with its reinforced stitching and toe protection, making sure your journey is never stopped short. Comfort? They have that covered too! The boots are a haven with their breathable materials, cushioned insole, with padded collar and tongue; all nestled neatly within their lightweight design. As they say, it's what's inside that counts - so inside you'll find a moisture-wicking lining that quarantines stank and keeps your feet fresh as that mountaintop breeze. Remember the fear of slippery surfaces? With these boots, you can finally tell it to 'take a hike'! Their shock-absorbing midsoles and excellent traction capabilities promise stability at your every step. Beautifully finished in a traditional lace-up system, every adventurer deserves a pair of TrekReady Hiking Boots. Hike more, worry less!\"\n5,BaseCamp Folding Table,60.0,Camping Tables,CampBuddy,\"CampBuddy's BaseCamp Folding Table is an adventurer's best friend. Lightweight yet powerful, the table is a testament to fun-meets-function and will elevate any outing to new heights. Crafted from resilient, rust-resistant aluminum, the table boasts a generously sized 48 x 24 inches tabletop, perfect for meal times, games and more. The foldable design is a godsend for on-the-go explorers. Adjustable legs rise to the occasion to conquer uneven terrains and offer height versatility, while the built-in handle simplifies transportation. Additional features like non-slip feet, integrated cup holders and mesh pockets add a pinch of finesse. Quick to set up without the need for extra tools, this table is a silent yet indispensable sidekick during camping, picnics, and other outdoor events. Don't miss out on the opportunity to take your outdoor experiences to a new level with the BaseCamp Folding Table. Get yours today and embark on new adventures tomorrow! \"\n6,EcoFire Camping Stove,80.0,Camping Stoves,EcoFire,\"Introducing EcoFire's Camping Stove, your ultimate companion for every outdoor adventure! This portable wonder is precision-engineered with a lightweight and compact design, perfect for capturing that spirit of wanderlust. Made from high-quality stainless steel, it promises durability and steadfast performance. This stove is not only fuel-efficient but also offers an easy, intuitive operation that ensures hassle-free cooking. Plus, it's flexible, accommodating a variety of cooking methods whether you're boiling, grilling, or simmering under the starry sky. Its stable construction, quick setup, and adjustable flame control make cooking a breeze, while safety features protect you from any potential mishaps. And did we mention it also includes an effective wind protector and a carry case for easy transportation? But that's not all! The EcoFire Camping Stove is eco-friendly, designed to minimize environmental impact. So get ready to enhance your camping experience and enjoy delicious outdoor feasts with this unique, versatile stove!\"\n7,CozyNights Sleeping Bag,100.0,Sleeping Bags,CozyNights,\"Embrace the great outdoors in any season with the lightweight CozyNights Sleeping Bag! This durable three-season bag is superbly designed to give hikers, campers, and backpackers comfort and warmth during spring, summer, and fall. With a compact design that folds down into a convenient stuff sack, you can whisk it away on any adventure without a hitch. The sleeping bag takes comfort seriously, featuring a handy hood, ample room and padding, and a reliable temperature rating. Crafted from high-quality polyester, it ensures long-lasting use and can even be zipped together with another bag for shared comfort. Whether you're gazing at stars or catching a quick nap between trails, the CozyNights Sleeping Bag makes it a treat. Don't just sleep\u2014 dream with CozyNights.\"\n8,Alpine Explorer Tent,350.0,Tents,AlpineGear,\"Welcome to the joy of camping with the Alpine Explorer Tent! This robust, 8-person, 3-season marvel is from the responsible hands of the AlpineGear brand. Promising an enviable setup that is as straightforward as counting sheep, your camping experience is transformed into a breezy pastime. Looking for privacy? The detachable divider provides separate spaces at a moment's notice. Love a tent that breathes? The numerous mesh windows and adjustable vents fend off any condensation dragon trying to dampen your adventure fun. The waterproof assurance keeps you worry-free during unexpected rain dances. With a built-in gear loft to stash away your outdoor essentials, the Alpine Explorer Tent emerges as a smooth balance of privacy, comfort, and convenience. Simply put, this tent isn't just a shelter - it's your second home in the heart of nature! Whether you're a seasoned camper or a nature-loving novice, this tent makes exploring the outdoors a joyous journey.\"\n9,SummitClimber Backpack,120.0,Backpacks,HikeMate,\"Adventure waits for no one! Introducing the HikeMate SummitClimber Backpack, your reliable partner for every exhilarating journey. With a generous 60-liter capacity and multiple compartments and pockets, packing is a breeze. Every feature points to comfort and convenience; the ergonomic design and adjustable hip belt ensure a pleasantly personalized fit, while padded shoulder straps protect you from the burden of carrying. Venturing into wet weather? Fear not! The integrated rain cover has your back, literally. Stay hydrated thanks to the backpack's hydration system compatibility. Travelling during twilight? Reflective accents keep you visible in low-light conditions. The SummitClimber Backpack isn't merely a carrier; it's a wearable base camp constructed from ruggedly durable nylon and thoughtfully designed for the great outdoors adventurer, promising to withstand tough conditions and provide years of service. So, set off on that quest - the wild beckons! The SummitClimber Backpack - your hearty companion on every expedition!\"\n10,TrailBlaze Hiking Pants,75.0,Hiking Clothing,MountainStyle,\"Meet the TrailBlaze Hiking Pants from MountainStyle, the stylish khaki champions of the trails. These are not just pants; they're your passport to outdoor adventure. Crafted from high-quality nylon fabric, these dapper troopers are lightweight and fast-drying, with a water-resistant armor that laughs off light rain. Their breathable design whisks away sweat while their articulated knees grant you the flexibility of a mountain goat. Zippered pockets guard your essentials, making them a hiker's best ally. Designed with durability for all your trekking trials, these pants come with a comfortable, ergonomic fit that will make you forget you're wearing them. Sneak a peek, and you are sure to be tempted by the sleek allure that is the TrailBlaze Hiking Pants. Your outdoors wardrobe wouldn't be quite complete without them.\"\n11,TrailWalker Hiking Shoes,110.0,Hiking Footwear,TrekReady,\"Meet the TrekReady TrailWalker Hiking Shoes, the ideal companion for all your outdoor adventures. Constructed with synthetic leather and breathable mesh, these shoes are tough as nails yet surprisingly airy. Their cushioned insoles offer fabulous comfort for long hikes, while the supportive midsoles and traction outsoles with multidirectional lugs ensure stability and excellent grip. A quick-lace system, padded collar and tongue, and reflective accents make these shoes a dream to wear. From combating rough terrain with the reinforced toe cap and heel, to keeping off trail debris with the protective mudguard, the TrailWalker Hiking Shoes have you covered. These waterproof warriors are made to endure all weather conditions. But they're not just about being rugged, they're light as a feather too, minimizing fatigue during epic hikes. Each pair can be customized for a perfect fit with removable insoles and availability in multiple sizes and widths. Navigate hikes comfortably and confidently with the TrailWalker Hiking Shoes. Adventure, here you come!\"\n12,TrekMaster Camping Chair,50.0,Camping Tables,CampBuddy,\"Gravitate towards comfort with the TrekMaster Camping Chair from CampBuddy. This trusty outdoor companion boasts sturdy construction using high-quality materials that promise durability and enjoyment for seasons to come. Impeccably lightweight and portable, it's designed to be your go-to seat whether you're camping, at a picnic, cheering at a sporting event, or simply relishing in your backyard pleasures. Beyond its foldable design ensuring compact storage and easy transportation, its ergonomic magic is in the details. An adjustable recline, padded seat and backrest, integrated cup holder, and side pockets ensure the greatest outdoor comfort. Weather resistant, easy to clean, and capable of supporting diverse body types, this versatile chair also comes with a carry bag, ready for your next adventure.\"\n13,PowerBurner Camping Stove,100.0,Camping Stoves,PowerBurner,\"Unleash your inner explorer with the PowerBurner Dual Burner Camping Stove. It's designed for the adventurous heart, with sturdy construction and a high heat output that makes boiling and cooking a breeze. This stove isn't just about strength\u2014it's got finesse too. With adjustable flame control, you can simmer, saut\u00e9, or sizzle with absolute precision. Its compact design and integrated carrying handle make transportation effortless. Moreover, it's crafted to defy the elements, boasting a wind-resistant exterior and piezo ignition system for quick, reliable starts. And when the cooking's done, its removable grates make cleanup swift and easy. Rugged, versatile and reliable, the PowerBurner marks a perfect blend of practicality and performance. So, why wait? Let's turn up the heat on your outdoor culinary adventures today.\"\n14,MountainDream Sleeping Bag,130.0,Sleeping Bags,MountainDream,\"Meet the MountainDream Sleeping Bag: your new must-have companion for every outdoor adventure. Designed to handle 3-season camping with ease, it comes equipped with a premium synthetic insulation that will keep you cozy even when temperatures fall down to 15\u00b0F! Sporting a durable water-resistant nylon shell and soft breathable polyester lining, this bag doesn't sacrifice comfort for toughness. The star of the show is the contoured mummy shape that not only provides optimal heat retention but also cuts down on the weight. A smooth, snag-free YKK zipper with a unique anti-snag design allows for hassle-free operation, while the adjustable hood and full-length zipper baffle work together to ensure you stay warm all night long. Need to bring along some essentials? Not to worry! There's an interior pocket just for that. And when it's time to pack up? Just slip it into the included compression sack for easy storage and transport. Whether you're a backpacking pro or a camping novice, the MountainDream Sleeping Bag is the perfect blend of durability, warmth, and comfort that you've been looking for.\"\n15,SkyView 2-Person Tent,200.0,Tents,OutdoorLiving,\"Introducing the OutdoorLiving SkyView 2-Person Tent, a perfect companion for your camping and hiking adventures. This tent offers a spacious interior that houses two people comfortably, with room to spare. Crafted from durable waterproof materials to shield you from the elements, it is the fortress you need in the wild. Setup is a breeze thanks to its intuitive design and color-coded poles, while two large doors allow for easy access. Stay organized with interior pockets, and store additional gear in its two vestibules. The tent also features mesh panels for effective ventilation, and it comes with a rainfly for extra weather protection. Light enough for on-the-go adventurers, it packs compactly into a carrying bag for seamless transportation. Reflective guy lines ensure visibility at night for added safety, and the tent stands freely for versatile placement. Experience the reliability of double-stitched seams that guarantee increased durability, and rest easy under the stars with OutdoorLiving's SkyView 2-Person Tent. It's not just a tent; it's your home away from home.\"\n16,TrailLite Daypack,60.0,Backpacks,HikeMate,\"Step up your hiking game with HikeMate's TrailLite Daypack. Built for comfort and efficiency, this lightweight and durable backpack offers a spacious main compartment, multiple pockets, and organization-friendly features all in one sleek package. The adjustable shoulder straps and padded back panel ensure optimal comfort during those long exhilarating treks. Course through nature without worry as the daypack's water-resistant fabric protects your essentials from unexpected showers. Plus, never run dry with the integrated hydration system. And did we mention it comes in a plethora of colors and designs? So you can choose one that truly speaks to your outdoorsy soul! Keeping your visibility in mind, we've added reflective accents that light up in low-light conditions. Don't just carry a backpack, adorn a companion that takes you a step ahead in your adventures. Trust the TrailLite Daypack for a hassle-free, enjoyable hiking experience.\"\n17,RainGuard Hiking Jacket,110.0,Hiking Clothing,MountainStyle,\"Introducing the MountainStyle RainGuard Hiking Jacket - the ultimate solution for weatherproof comfort during your outdoor undertakings! Designed with waterproof, breathable fabric, this jacket promises an outdoor experience that's as dry as it is comfortable. The rugged construction assures durability, while the adjustable hood provides a customizable fit against wind and rain. Featuring multiple pockets for safe, convenient storage and adjustable cuffs and hem, you can tailor the jacket to suit your needs on-the-go. And, don't worry about overheating during intense activities - it's equipped with ventilation zippers for increased airflow. Reflective details ensure visibility even during low-light conditions, making it perfect for evening treks. With its lightweight, packable design, carrying it inside your backpack requires minimal effort. With options for men and women, the RainGuard Hiking Jacket is perfect for hiking, camping, trekking and countless other outdoor adventures. Don't let the weather stand in your way - embrace the outdoors with MountainStyle RainGuard Hiking Jacket!\"\n18,TrekStar Hiking Sandals,70.0,Hiking Footwear,TrekReady,\"Meet the TrekStar Hiking Sandals from TrekReady - the ultimate trail companion for your feet. Designed for comfort and durability, these lightweight sandals are perfect for those who prefer to see the world from a hiking trail. They feature adjustable straps for a snug, secure fit, perfect for adapting to the contours of your feet. With a breathable design, your feet will stay cool and dry, escaping the discomfort of sweaty hiking boots on long summer treks. The deep tread rubber outsole ensures excellent traction on any terrain, while the cushioned footbed promises enhanced comfort with every step. For those wild and unpredictable trails, the added toe protection and shock-absorbing midsole protect your feet from rocky surprises. Ingeniously, the removable insole makes for easy cleaning and maintenance, extending the lifespan of your sandals. Available in various sizes and a handsome brown color, the versatile TrekStar Hiking Sandals are just as comfortable on a casual walk in the park as they are navigating rocky slopes. Explore more with TrekReady!\"\n19,Adventure Dining Table,90.0,Camping Tables,CampBuddy,\"Discover the joy of outdoor adventures with the CampBuddy Adventure Dining Table. This feature-packed camping essential brings both comfort and convenience to your memorable trips. Made from high-quality aluminum, it promises long-lasting performance, weather resistance, and easy maintenance - all key for the great outdoors! It's light, portable, and comes with adjustable height settings to suit various seating arrangements and the spacious surface comfortably accommodates meals, drinks, and other essentials. The sturdy yet lightweight frame holds food, dishes, and utensils with ease. When it's time to pack up, it fold and stows away with no fuss, ready for the next adventure!  Perfect for camping, picnics, barbecues, and beach outings - its versatility shines as brightly as the summer sun! Durable, sturdy and a breeze to set up, the Adventure Dining Table will be a loyal companion on every trip. Embark on your next adventure and make lifetime memories with CampBuddy. As with all good experiences, it'll leave you wanting more! \"\n20,CompactCook Camping Stove,60.0,Camping Stoves,CompactCook,\"Step into the great outdoors with the CompactCook Camping Stove, a convenient, lightweight companion perfect for all your culinary camping needs. Boasting a robust design built for harsh environments, you can whip up meals anytime, anywhere. Its wind-resistant and fuel-versatile features coupled with an efficient cooking performance, ensures you won't have to worry about the elements or helpless taste buds while on adventures. The easy ignition technology and adjustable flame control make cooking as easy as a walk in the park, while its compact, foldable design makes packing a breeze. Whether you're camping with family or hiking solo, this reliable, portable stove is an essential addition to your gear. With its sturdy construction and safety-focused design, the CompactCook Camping Stove is a step above the rest, providing durability, quality, and peace of mind. Be wild, be free, be cooked for with the CompactCook Camping Stove!\"\n</code></pre>"},{"location":"Sample-Workshop/3-Ideate/02/","title":"3.2 Create Search Index","text":""},{"location":"Sample-Workshop/3-Ideate/02/#1-create-search-index-script","title":"1. Create Search Index Script","text":"<p>Let's copy over the <code>create-search-index.py</code> script into our application source folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/create-search-index.py  src/api/.\n</code></pre> </li> </ol>"},{"location":"Sample-Workshop/3-Ideate/02/#2-understand-index-creation","title":"2. Understand Index Creation","text":"<p>Now, let's take a look at what this does.</p> Click to expand and view the Python Script to create the search index src/api/create-search-index.py<pre><code>    import os\n    from azure.ai.projects import AIProjectClient\n    from azure.ai.projects.models import ConnectionType\n    from azure.identity import DefaultAzureCredential\n    from azure.core.credentials import AzureKeyCredential\n    from azure.search.documents import SearchClient\n    from azure.search.documents.indexes import SearchIndexClient\n    from config import get_logger\n\n    # initialize logging object\n    logger = get_logger(__name__)\n\n    # create a project client using environment variables loaded from the .env file\n    project = AIProjectClient.from_connection_string(\n        conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"], credential=DefaultAzureCredential()\n    )\n\n    # create a vector embeddings client that will be used to generate vector embeddings\n    embeddings = project.inference.get_embeddings_client()\n\n    # use the project client to get the default search connection\n    search_connection = project.connections.get_default(\n        connection_type=ConnectionType.AZURE_AI_SEARCH, include_credentials=True\n    )\n\n    # Create a search index client using the search connection\n    # This client will be used to create and delete search indexes\n    index_client = SearchIndexClient(\n        endpoint=search_connection.endpoint_url, credential=AzureKeyCredential(key=search_connection.key)\n    )\n</code></pre> <p>First the script sets up a search index_client:</p> <ol> <li>Creates an Azure AI Project Client instance (configured with connection string)</li> <li>Retrieves an <code>embeddings</code> inference client from the AI project (maps to that model)</li> <li>Retrieves a <code>search_connection</code> object from the AI project instance</li> <li>Creates an <code>index_client</code> search index client using the search connection (key, endpoint)</li> </ol> <p>First it  defines the index based on a vector derived from product data fields.</p> <ol> <li>It maps product name to a title property</li> <li>It maps product description to a content property</li> <li>It uses HNSW algorithm (cosine distance) for similarity</li> <li>It prioritizes \"content\" for semantic ranking</li> </ol> <p>It then creates the index from CSV and populates it using the index_client.</p> <ol> <li>It defines an index using the specified name and embeddings model</li> <li>It loads CSV and generates vector embeddings for each <code>description</code> </li> <li>It uploads each vectorized document into the pre-defined search index</li> </ol>"},{"location":"Sample-Workshop/3-Ideate/02/#3-run-index-creation-script","title":"3. Run Index Creation Script","text":"<p>To get the index created in Azure AI Search, </p> <ol> <li> <p>Change to the <code>src/api</code> folder </p> <pre><code>cd src/api\n</code></pre> </li> <li> <p>Run the script:</p> <pre><code>python create-search-index.py\n</code></pre> </li> </ol>"},{"location":"Sample-Workshop/3-Ideate/02/#4-verify-search-index","title":"4. Verify Search Index","text":"<p>Then verify that the index was created successfully:</p> <ol> <li>Visit the Azure Portal and look up your Resource Group</li> <li>Visit the Azure AI Search resource page from that RG</li> <li>Click on \"Search Explorer\" from the resource overview page</li> <li>Click \"Search\" - verify that you see indexed products</li> </ol>"},{"location":"Sample-Workshop/3-Ideate/03/","title":"3.3 Retrieve Related Products","text":""},{"location":"Sample-Workshop/3-Ideate/03/#1-add-docs-retrieval-script","title":"1. Add Docs Retrieval Script","text":"<p>Let's copy over the <code>get_product_documents.py</code> script into our application source folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/get_product_documents.py  src/api/.\n</code></pre> </li> </ol>"},{"location":"Sample-Workshop/3-Ideate/03/#2-understand-docs-retrieval","title":"2. Understand Docs Retrieval","text":"<p>Let's start with a sample user query like this:</p> <pre><code> I need a new tent for 4 people, what would you recommend?\n</code></pre> <p>Different users could phrase the question in different ways, with different levels of information. But we need to map all these queries to a search query that works on the product database. How do we do that? We use a 3-step process:</p> <ol> <li>We teach an AI to extract user intent from an input text query</li> <li>We teach the AI  to map user intent to a search query on products</li> <li>We use the search index to retrieve product documents matching query.</li> </ol> <p>Let's see how we do this.</p>"},{"location":"Sample-Workshop/3-Ideate/03/#3-create-ai-project-client","title":"3. Create AI Project Client","text":"<ol> <li>Create an Azure AI Project client using the connection string</li> <li>Use the client to retrieve a <code>chat_completions</code> inference client</li> <li>Use the client to retrieve an <code>embeddings</code> inference client</li> <li>Use the client to setup a <code>search_client</code> using the search connection</li> </ol> Click to expand and view the Python script src/api/get_product_documents.py - Part 1<pre><code># ----------------------------------------------\n# 1. Create Search Index Client \n# ----------------------------------------------\nimport os\nfrom pathlib import Path\nfrom opentelemetry import trace\nfrom azure.ai.projects import AIProjectClient\nfrom azure.ai.projects.models import ConnectionType\nfrom azure.identity import DefaultAzureCredential\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents import SearchClient\nfrom config import ASSET_PATH, get_logger\n\n# initialize logging and tracing objects\nlogger = get_logger(__name__)\ntracer = trace.get_tracer(__name__)\n\n# create a project client using environment variables loaded from the .env file\nproject = AIProjectClient.from_connection_string(\n    conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"], credential=DefaultAzureCredential()\n)\n\n# create a vector embeddings client that will be used to generate vector embeddings\nchat = project.inference.get_chat_completions_client()\nembeddings = project.inference.get_embeddings_client()\n\n# use the project client to get the default search connection\nsearch_connection = project.connections.get_default(\n    connection_type=ConnectionType.AZURE_AI_SEARCH, include_credentials=True\n)\n\n# Create a search index client using the search connection\n# This client will be used to create and delete search indexes\nsearch_client = SearchClient(\n    index_name=os.environ[\"AISEARCH_INDEX_NAME\"],\n    endpoint=search_connection.endpoint_url,\n    credential=AzureKeyCredential(key=search_connection.key),\n)\n</code></pre>"},{"location":"Sample-Workshop/3-Ideate/03/#4-get-docs-for-user-intent","title":"4. Get Docs For User Intent","text":"<ol> <li>First, receive input text string (user query)</li> <li>Then, map user query text into a clear intent (search query)</li> <li>Then, vectorize the search query (to support retrieval)</li> <li>Then, search the product index for matches (by cosine similarity)</li> <li>Then, for each matching product, retrieve its document (content)</li> <li>Return the collection of documents to the user.</li> </ol> Click to expand and view the Python script src/api/get_product_documents.py - Part 2<pre><code>    # ----------------------------------------------\n    # 2. Define Function to Get Product Documents\n    # ----------------------------------------------\n    from azure.ai.inference.prompts import PromptTemplate\n    from azure.search.documents.models import VectorizedQuery\n\n    @tracer.start_as_current_span(name=\"get_product_documents\")\n    def get_product_documents(messages: list, context: dict = None) -&gt; dict:\n        if context is None:\n            context = {}\n\n        overrides = context.get(\"overrides\", {})\n        top = overrides.get(\"top\", 5)\n\n        # generate a search query from the chat messages\n        intent_prompty = PromptTemplate.from_prompty(Path(ASSET_PATH) / \"intent_mapping.prompty\")\n\n        intent_mapping_response = chat.complete(\n            model=os.environ[\"INTENT_MAPPING_MODEL\"],\n            messages=intent_prompty.create_messages(conversation=messages),\n            **intent_prompty.parameters,\n        )\n\n        # the search_query returned here will be a stringified JSON object\n        search_query = intent_mapping_response.choices[0].message.content\n        logger.debug(f\"\ud83e\udde0 Intent mapping: {search_query}\")\n\n        # -- OLD: generate a vector representation of the search query\n        # embedding = embeddings.embed(model=os.environ[\"EMBEDDINGS_MODEL\"], input=search_query)\n\n        # --- NEW: generate a vector representation of the search query\n        #  The intent mapping response is a stringied JSON object \n        #   with the intent and search_query components. We need to\n        #   extract the search_query term and create embedding from it\n        import json\n        intent_map = json.loads(search_query)\n        embedding = embeddings.embed(model=os.environ[\"EMBEDDINGS_MODEL\"], input=intent_map[\"search_query\"])\n        search_vector = embedding.data[0].embedding\n        # --- END\n\n        # search the index for products matching the search query\n        vector_query = VectorizedQuery(vector=search_vector, k_nearest_neighbors=top, fields=\"contentVector\")\n\n        search_results = search_client.search(\n            search_text=search_query, vector_queries=[vector_query], select=[\"id\", \"content\", \"filepath\", \"title\", \"url\"]\n        )\n\n        documents = [\n            {\n                \"id\": result[\"id\"],\n                \"content\": result[\"content\"],\n                \"filepath\": result[\"filepath\"],\n                \"title\": result[\"title\"],\n                \"url\": result[\"url\"],\n            }\n            for result in search_results\n        ]\n\n        # add results to the provided context\n        if \"thoughts\" not in context:\n            context[\"thoughts\"] = []\n\n        # add thoughts and documents to the context object so it can be returned to the caller\n        context[\"thoughts\"].append(\n            {\n                \"title\": \"Generated search query\",\n                \"description\": search_query,\n            }\n        )\n\n        if \"grounding_data\" not in context:\n            context[\"grounding_data\"] = []\n        context[\"grounding_data\"].append(documents)\n\n        logger.debug(f\"\ud83d\udcc4 {len(documents)} documents retrieved: {documents}\")\n        return documents\n</code></pre>"},{"location":"Sample-Workshop/3-Ideate/03/#5-run-docs-retrieval-script","title":"5. Run Docs Retrieval Script","text":"<p>Before we can run this script, we need to create the Intent Mapper template for step 2. Let's do that next.</p>"},{"location":"Sample-Workshop/3-Ideate/04/","title":"3.4 Understand Intent Mapping","text":""},{"location":"Sample-Workshop/3-Ideate/04/#1-add-intent-mapping-prompty","title":"1. Add Intent Mapping Prompty","text":"<p>Let's copy over the <code>intent_mapping.prompty</code> prompt template into our assets folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/assets/intent_mapping.prompty src/api/assets/.\n</code></pre> </li> </ol>"},{"location":"Sample-Workshop/3-Ideate/04/#2-run-docs-retrieval-script","title":"2. Run Docs Retrieval Script","text":"<p>Before we dive into the details of that file, let's first run the document retrieval script and see what happens. Here's an example with the question we discussed earlier.</p> <ol> <li> <p>Change to the <code>src/api</code> folder </p> <pre><code>cd src/api\n</code></pre> </li> <li> <p>Run the script:</p> <pre><code>python get_product_documents.py --query \"I need a new tent for 4 people, what would you recommend?\"\n</code></pre> </li> <li> <p>Observe the response. It may look like this:</p> <pre><code>\ud83e\udde0 Intent mapping: {\n    \"intent\": \"The user is looking for recommendations for a tent suitable for 4 people.\",\n    \"search_query\": \"best tents for 4 people\"\n}\n</code></pre> </li> </ol> <p>The script output shows that it extracted the user intent and formulated a search query from it that related to a product (\"best tents for 4 people\") - and can be answered by the search index.</p>"},{"location":"Sample-Workshop/3-Ideate/04/#3-intent-mapping-in-action","title":"3. Intent Mapping In Action","text":"<p>The intent mapping is achieved using a Prompty asset - a YAML file that consists of frontmatter (prompt metdata) and content (prompt template)</p> <ul> <li>Frontmatter defines model configuration and prompt inputs</li> <li>Template defines prompt structure, context and instructions</li> </ul> <p>Looking into the details of the prompt template, we can see it employs a few-shot learning technique where it attempts to teach the AI to execute a specific task (extract intent) by providing it with examples of inputs and expected responses.</p> Click to expand and view Intent Mapping Prompty src/api/assets/intent_mapping.prompty<pre><code> ---\nname: Chat Prompt\ndescription: A prompty that extract users query intent based on the current_query and chat_history of the conversation\nmodel:\n    api: chat\n    configuration:\n        azure_deployment: gpt-4o\ninputs:\n    conversation:\n        type: array\n---\nsystem:\n# Instructions\n- You are an AI assistant reading a current user query and chat_history.\n- Given the chat_history, and current user's query, infer the user's intent expressed in the current user query.\n- Once you infer the intent, respond with a search query that can be used to retrieve relevant documents for the current user's query based on the intent\n- Be specific in what the user is asking about, but disregard parts of the chat history that are not relevant to the user's intent.\n- Provide responses in json format\n\n# Examples\nExample 1:\nWith a conversation like below:\n    ```\n    - user: are the trailwalker shoes waterproof?\n    - assistant: Yes, the TrailWalker Hiking Shoes are waterproof. They are designed with a durable and waterproof construction to withstand various terrains and weather conditions.\n    - user: how much do they cost?\n    ```\nRespond with:\n{\n    \"intent\": \"The user wants to know how much the Trailwalker Hiking Shoes cost.\",\n    \"search_query\": \"price of Trailwalker Hiking Shoes\"\n}\n\nExample 2:\nWith a conversation like below:\n    ```\n    - user: are the trailwalker shoes waterproof?\n    - assistant: Yes, the TrailWalker Hiking Shoes are waterproof. They are designed with a durable and waterproof construction to withstand various terrains and weather conditions.\n    - user: how much do they cost?\n    - assistant: The TrailWalker Hiking Shoes are priced at $110.\n    - user: do you have waterproof tents?\n    - assistant: Yes, we have waterproof tents available. Can you please provide more information about the type or size of tent you are looking for?\n    - user: which is your most waterproof tent?\n    - assistant: Our most waterproof tent is the Alpine Explorer Tent. It is designed with a waterproof material and has a rainfly with a waterproof rating of 3000mm. This tent provides reliable protection against rain and moisture.\n    - user: how much does it cost?\n    ```\nRespond with:\n{\n    \"intent\": \"The user would like to know how much the Alpine Explorer Tent costs.\",\n    \"search_query\": \"price of Alpine Explorer Tent\"\n}\n\nuser:\nReturn the search query for the messages in the following conversation:\n{{#conversation}}\n- {{role}}: {{content}}\n{{/conversation}}\n</code></pre>"},{"location":"Sample-Workshop/3-Ideate/05/","title":"3.5 Create Augmented Query","text":""},{"location":"Sample-Workshop/3-Ideate/05/#1-add-chat-with-products-script","title":"1. Add Chat With Products Script","text":"<p>Let's copy over the <code>chat_with_products.py</code> script into our application source.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/chat_with_products.py src/api/.\n</code></pre> </li> </ol>"},{"location":"Sample-Workshop/3-Ideate/05/#2-understand-rag-workflow","title":"2. Understand RAG Workflow","text":"<p>This script is the core orchestrator for our RAG workflow, executing the following steps:</p> <ol> <li>Create an Azure AI Project client (with connection string)</li> <li>Retrieve the inference client for chat completions model</li> <li>Use incoming user messages to retrieve related products</li> <li>Use this knowledge to populate a grounded chat template</li> <li>Call the chat completions client with this prompt template</li> </ol> Click to expand and view Chat With Products script (segment) src/api/chat_with_products.py<pre><code>from azure.ai.inference.prompts import PromptTemplate\n\n\n@tracer.start_as_current_span(name=\"chat_with_products\")\ndef chat_with_products(messages: list, context: dict = None) -&gt; dict:\n    if context is None:\n        context = {}\n\n    documents = get_product_documents(messages, context)\n\n    # do a grounded chat call using the search results\n    grounded_chat_prompt = PromptTemplate.from_prompty(Path(ASSET_PATH) / \"grounded_chat.prompty\")\n\n    system_message = grounded_chat_prompt.create_messages(documents=documents, context=context)\n    response = chat.complete(\n        model=os.environ[\"CHAT_MODEL\"],\n        messages=system_message + messages,\n        **grounded_chat_prompt.parameters,\n    )\n    logger.info(f\"\ud83d\udcac Response: {response.choices[0].message}\")\n\n    # Return a chat protocol compliant response\n    return {\"message\": response.choices[0].message, \"context\": context}\n</code></pre> <p>In the next section, we'll look at the prompt template and run a test with a sample query.</p>"},{"location":"Sample-Workshop/3-Ideate/05/#3-run-chat-with-products-script","title":"3. Run Chat With Products Script","text":"<p>Before we can run this script, we need to create the Grounded Chat Prompt template for step 4. Let's do that next.</p>"},{"location":"Sample-Workshop/3-Ideate/06/","title":"3.6 Design Grounded Prompt","text":""},{"location":"Sample-Workshop/3-Ideate/06/#1-add-grounded-chat-prompty","title":"1. Add Grounded Chat Prompty","text":"<p>Let's copy over the <code>grounded_chat.prompty</code> prompt template into our assets folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/assets/grounded_chat.prompty src/api/assets/.\n</code></pre> </li> </ol>"},{"location":"Sample-Workshop/3-Ideate/06/#2-understand-grounding-context","title":"2. Understand Grounding Context","text":"<p>Explore the contents of this template. Notice how the <code>system</code> context provides clear instructions and guidance to ensure quality responses. This includes grounding responses in context (when query is relevant) and declining to provide responses (when query is irrelevant).</p> Click to expand and view Grounded Chat Prompty src/api/assets/grounded_chat.prompty<pre><code>    ---\n    name: Chat with documents\n    description: Uses a chat completions model to respond to queries grounded in relevant documents\n    model:\n        api: chat\n        configuration:\n            azure_deployment: gpt-4o\n    inputs:\n        conversation:\n            type: array\n    ---\n    system:\n    You are an AI assistant helping users with queries related to outdoor outdooor/camping gear and clothing.\n    If the question is not related to outdoor/camping gear and clothing, just say 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?'\n    Don't try to make up any answers.\n    If the question is related to outdoor/camping gear and clothing but vague, ask for clarifying questions instead of referencing documents. If the question is general, for example it uses \"it\" or \"they\", ask the user to specify what product they are asking about.\n    Use the following pieces of context to answer the questions about outdoor/camping gear and clothing as completely, correctly, and concisely as possible.\n    Do not add documentation reference in the response.\n\n    # Documents\n\n    {{#documents}}\n\n    ## Document {{id}}: {{title}}\n    {{content}}\n    {{/documents}}\n</code></pre>"},{"location":"Sample-Workshop/3-Ideate/06/#3-chat-with-products-relevant","title":"3. Chat With Products - Relevant","text":"<p>Run the script with a test query (from the <code>src/api</code> folder). </p> <ol> <li> <p>Change to the <code>src/api</code> folder </p> <pre><code>cd src/api\n</code></pre> </li> <li> <p>Run the script:</p> <pre><code>python chat_with_products.py --query \"I need a new tent for 4 people, what would you recommend?\"\n</code></pre> </li> <li> <p>Observe the response. It may look like this:</p> <pre><code>\ud83d\udcac Response: {'content': \"I recommend the TrailMaster X4 Tent. It is specifically designed to accommodate four occupants comfortably. The tent features durable water-resistant construction, multiple doors for easy access, and mesh panels for ventilation and bug protection. Additionally, it has a freestanding design for easy setup and relocation, as well as interior pockets for organization. It's a great choice for your camping adventures!\", 'role': 'assistant'}\n</code></pre> </li> </ol> <p>Is the response grounded in product data from the catalog? </p>"},{"location":"Sample-Workshop/3-Ideate/06/#4-chat-with-products-irrelevant","title":"4. Chat With Products - Irrelevant","text":"<p>Try asking a question that does not relate to the hiking and camping topic:</p> <ol> <li> <p>Verify you are still in the <code>src/api</code> folder. </p> </li> <li> <p>Then run this script:</p> <pre><code>python chat_with_products.py --query \"I am looking for a recipe for spicy bean burgers\"\n</code></pre> </li> <li> <p>Observe the response. It may look like this:</p> <pre><code>\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n</code></pre> </li> </ol> <p>Is this response relevant and grounded in the context for this application? </p>"},{"location":"Sample-Workshop/3-Ideate/07/","title":"3.7 Test with Observability","text":"<p>Recall that we activated Application Insights during the setup phase of our project. This now allows to ask questions with telemetry enabled and get observable traces using open telemetry, to help us analyze the cost or performance of our workflows.</p> <p>Let's see this in action.</p>"},{"location":"Sample-Workshop/3-Ideate/07/#1-enable-telemetry-on-test","title":"1. Enable Telemetry on Test","text":"<ol> <li> <p>Change to the <code>src/api</code> folder </p> <pre><code>cd src/api\n</code></pre> </li> <li> <p>Run the script: Run the <code>Chat with Products</code> script with <code>--enable-telemetry</code> as shown.</p> <pre><code>python chat_with_products.py --query \"I need hiking gear for a trip to Andalusia - what tents and boots do you recommend?\" --enable-telemetry\n</code></pre> </li> <li> <p>You should see something like this in the console. Let's explore this next.</p> <pre><code>Enabled telemetry logging to project, view traces at:\nhttps://ai.azure.com/tracing?wsid=/subscriptions/XXXX/resourceGroups/ninarasi-ragchat-rg/providers/Microsoft.MachineLearningServices/workspaces/ninarasi-ragchat-v1\n\ud83d\udcac Response: {'content': \"For your trip to Andalusia, I recommend the following tents and boots:\\n\\n**Tents:**\\n1. **Alpine Explorer Tent**: This robust, 8-person, 3-season tent is perfect for group camping. It has multiple mesh windows for ventilation and a detachable divider for privacy. Its waterproof feature ensures you stay dry during unexpected rain.\\n\\n2. **SkyView 2-Person Tent**: If you're looking for a smaller option, this tent comfortably houses two people and is made from durable waterproof materials. It also features an intuitive setup system, effective ventilation, and a rainfly for extra weather protection, making it great for hiking and camping.\\n\\n**Boots:**\\n1. **TrekReady Hiking Boots**: These boots are crafted from leather, ensuring durability and comfort on long hikes. They have a moisture-wicking lining, shock-absorbing midsoles, and excellent traction, making them suitable for various terrains.\\n\\n2. **TrekStar Hiking Sandals**: If you prefer something lighter and more breathable, consider these lightweight sandals. They offer adjustable straps, excellent traction, toe protection, and a cushioned footbed for comfort during summer treks.\\n\\nChoose based on your group size and hiking preferences, and you'll be well-prepared for your adventure in Andalusia!\", 'role': 'assistant'}\n</code></pre> </li> </ol>"},{"location":"Sample-Workshop/3-Ideate/07/#2-view-traces-detail","title":"2. View Traces Detail","text":"<p>Look for the output section with a link as shown below, and navigate to that URL in the browser.</p> <pre><code>Enabled telemetry logging to project, view traces at:\nhttps://ai.azure.com/tracing?....\n</code></pre> <p>It will take a few minutes for the traces to show up. Refresh periodically to see results.</p> <p>You should see something like this reflecting the latest run of the Chat with Products script above. Click to expand the tree of nodes on the left and observe the details provided in the panel on the right, as you step through them.</p> <ol> <li>We can trace the flow of control from the user query to the returned response</li> <li>We can measure the time taken for each step to execute (in seconds)</li> <li>We can observe the cost for model invocations (in tokens) in the GenAI rows</li> <li>For a given model interaction, we can explore details (system, user, assistant) to debug</li> </ol> <p></p>"},{"location":"Sample-Workshop/3-Ideate/07/#3-view-traces-dashboard","title":"3. View Traces Dashboard","text":"<p>Click on the Tracing menu option in the sidebar to get the historical logs from previous runs. This is an effective way to analyze issues in cost or performance, make changes, then compare trace runs to see if the iterations had any impact.</p> <p></p>"},{"location":"Sample-Workshop/3-Ideate/07/#4-view-traces-insights","title":"4. View Traces Insights","text":"<p>You can also click on the <code>Insights for Generative AI Applications Dashboard</code> link (top of screen) to get a more actionable Generative AI Application Insights (Preview) dashboard for real-time insights and analysis of usage patterns.</p> <p></p>"},{"location":"Sample-Workshop/4-Evaluate/01/","title":"4.1 Create Evaluation Dataset","text":"<p>This begins Part 3 of the tutorial. This stage is completed USING THE AZURE AI FOUNDRY SDK.</p> <p>At the end of this section, you should have established an evaluation inputs dataset, created an evaluation script for AI-assisted evaluation, and run the script to assess the chat AI app for quality. You will then learn to explore the evaluation outcomes locally, and via the Azure AI Foundry portal, and understand how to customize and automate the process for rapid iteration and improvement of your application quality.</p>"},{"location":"Sample-Workshop/4-Evaluate/01/#1-evaluating-generative-ai-apps","title":"1. Evaluating Generative AI Apps","text":"<p>The evaluation phase is critical to assessing the quality and safety of your generative AI application. The Azure AI Foundry provides a comprehensive set of tools and guidance to support evaluation in three dimensions. Learn More Here.</p> <p></p> <ol> <li>Risk and safety evaluators: Evaluating potential risks associated with AI-generated content. Ex: evaluating AI predisposition towards generating harmful or inappropriate content.</li> <li>Performance and quality evaluators: Assessing accuracy, groundedness, and relevance of generated content using robust AI-assisted and Natural Language Processing (NLP) metrics.</li> <li>Custom evaluators: Tailored evaluation metrics that allow for more detailed and specific analyses. Ex: addressing app-specific requirements not covered by standard metrics.</li> </ol> <p>AI-Assisted Evaluators are available only in select regions (Recommended: East US 2)</p>"},{"location":"Sample-Workshop/4-Evaluate/01/#2-ai-assisted-evaluation-flow","title":"2. AI-Assisted Evaluation Flow","text":"<p>So far, we've tested the chat application interactively (command-line) using a single test prompt. Now, we want to evaluate the responses on a larger and more diverse set of test prompts including edge cases. We can then use those results to iterate on our application (e.g., prompt template, data sources) till evaluations pass our acceptance criteria.</p> <p>To do this we use AI-Assisted Evaluation - also referred to as LLM-as-a-judge - where we ask a second AI model (\"judge\") to grade the responses of the first AI model (\"target\"). The workflow is as shown below:</p> <ol> <li>First, create an evaluation dataset that consists of diverse queries for testing.</li> <li>Next, have the target AI (app) generate responses for each query</li> <li>Next, have the judge AI (assessor) grade tge {query, response} pairs </li> <li>Finally, visualize results (individual vs. aggregate metrics) for review.</li> </ol> <p></p>"},{"location":"Sample-Workshop/4-Evaluate/01/#3-create-evaluation-dataset","title":"3. Create Evaluation Dataset","text":"<p>Let's copy over the <code>chat_eval_data.jsonl</code> dataset into our assets folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li>Then run this command:</li> </ol> <pre><code>cp src.sample/api/assets/chat_eval_data.jsonl src/api/assets/.\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/01/#4-review-evaluation-dataset","title":"4. Review Evaluation Dataset","text":"<p>The Azure AI Foundry supports different data formats for evaluation including:</p> <ol> <li>Query/Response - each result has the query, response, and ground truth.</li> <li>Conversation (single/multi-turn) - messages (with content, role, optional context)</li> </ol> Click to expand and view the evaluation dataset src/api/assets/chat_eval_data.jsonl<pre><code>{\"query\": \"Which tent is the most waterproof?\", \"truth\": \"The Alpine Explorer Tent has the highest rainfly waterproof rating at 3000m\"}\n{\"query\": \"Which camping table holds the most weight?\", \"truth\": \"The Adventure Dining Table has a higher weight capacity than all of the other camping tables mentioned\"}\n{\"query\": \"How much do the TrailWalker Hiking Shoes cost? \", \"truth\": \"The Trailewalker Hiking Shoes are priced at $110\"}\n{\"query\": \"What is the proper care for trailwalker hiking shoes? \", \"truth\": \"After each use, remove any dirt or debris by brushing or wiping the shoes with a damp cloth.\"}\n{\"query\": \"What brand is TrailMaster tent? \", \"truth\": \"OutdoorLiving\"}\n{\"query\": \"How do I carry the TrailMaster tent around? \", \"truth\": \" Carry bag included for convenient storage and transportation\"}\n{\"query\": \"What is the floor area for Floor Area? \", \"truth\": \"80 square feet\"}\n{\"query\": \"What is the material for TrailBlaze Hiking Pants?\", \"truth\": \"Made of high-quality nylon fabric\"}\n{\"query\": \"What color does TrailBlaze Hiking Pants come in?\", \"truth\": \"Khaki\"}\n{\"query\": \"Can the warrenty for TrailBlaze pants be transfered? \", \"truth\": \"The warranty is non-transferable and applies only to the original purchaser of the TrailBlaze Hiking Pants. It is valid only when the product is purchased from an authorized retailer.\"}\n{\"query\": \"How long are the TrailBlaze pants under warranty for? \", \"truth\": \" The TrailBlaze Hiking Pants are backed by a 1-year limited warranty from the date of purchase.\"}\n{\"query\": \"What is the material for PowerBurner Camping Stove? \", \"truth\": \"Stainless Steel\"}\n{\"query\": \"Is France in Europe?\", \"truth\": \"Sorry, I can only queries related to outdoor/camping gear and equipment\"}\n</code></pre> <p>Our dataset reflects the first format, where the test prompts contain a query with the ground truth for evaluating responses. The chat AI will then generate a response (based on query) that gets added to this record, to create the evaluation dataset that is sent to the \"judge\" AI.</p> <p><pre><code> {\n    \"query\": \"Which tent is the most waterproof?\", \n    \"truth\": \"The Alpine Explorer Tent has the highest rainfly waterproof rating at 3000m\"\n}\n</code></pre> Let's look at the evaluation script that orchestrates this workflow, next</p>"},{"location":"Sample-Workshop/4-Evaluate/02/","title":"4.2 Create Evaluation Script","text":""},{"location":"Sample-Workshop/4-Evaluate/02/#1-create-evaluation-script","title":"1. Create Evaluation Script","text":"<p>Let's copy over the <code>evaluate.py</code> script into our application source folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li>Then run this command:</li> </ol> <pre><code>cp src.sample/api/evaluate.py  src/api/.\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/02/#2-review-evaluation-workflow","title":"2. Review Evaluation Workflow","text":"<p>Let's review the workflow required for AI-Assisted evaluation:</p> <ol> <li>We have an evaluation test dataset containing query/truth pairs</li> <li>We have a target AI (applicationl) that will generate the responses</li> <li>We have a judge AI (evaluator) that will grade those responses</li> <li>The judge has scoring criteria they use to generate evaluation metrics</li> <li>The evaluation results are published locally, or to Azure AI Foundry</li> </ol> <p></p>"},{"location":"Sample-Workshop/4-Evaluate/02/#3-unpack-evaluation-script","title":"3. Unpack Evaluation Script","text":""},{"location":"Sample-Workshop/4-Evaluate/02/#31-create-ai-project-client","title":"3.1 Create AI Project Client","text":"src/api/evaluate.py<pre><code>    # ----------------------------------------------\n    # 1. Create AI Project Client \n    # ----------------------------------------------\n    import os\n    import pandas as pd\n    from azure.ai.projects import AIProjectClient\n    from azure.ai.projects.models import ConnectionType\n    from azure.ai.evaluation import evaluate, GroundednessEvaluator\n    from azure.identity import DefaultAzureCredential\n\n    from chat_with_products import chat_with_products\n\n    # load environment variables from the .env file at the root of this repo\n    from dotenv import load_dotenv\n    load_dotenv()\n\n    # create a project client using environment variables loaded from the .env file\n    project = AIProjectClient.from_connection_string(\n        conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"], credential=DefaultAzureCredential()\n    )\n\n    connection = project.connections.get_default(connection_type=ConnectionType.AZURE_OPEN_AI, include_credentials=True)\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/02/#32-specify-model-evaluators","title":"3.2 Specify Model &amp; Evaluators","text":"src/api/evaluate.py<pre><code>    # ----------------------------------------------\n    # 2. Define Evaluator Model to use\n    # ----------------------------------------------\n    evaluator_model = {\n        \"azure_endpoint\": connection.endpoint_url,\n        \"azure_deployment\": os.environ[\"EVALUATION_MODEL\"],\n        \"api_version\": \"2024-06-01\",\n        \"api_key\": connection.key,\n    }\n\n    groundedness = GroundednessEvaluator(evaluator_model)\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/02/#33-create-evaluation-wrapper","title":"3.3 Create Evaluation Wrapper","text":"src/api/evaluate.py<pre><code>    # ----------------------------------------------\n    # 3. Create Eval Wrapper Function for Query\n    # ----------------------------------------------\n    def evaluate_chat_with_products(query):\n        response = chat_with_products(messages=[{\"role\": \"user\", \"content\": query}])\n        return {\"response\": response[\"message\"].content, \"context\": response[\"context\"][\"grounding_data\"]}\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/02/#34-run-evaluation-print","title":"3.4 Run Evaluation &amp; Print","text":"<p>This is the entry point for the evaluation script. </p> <ul> <li>It uses the evaluate function from the <code>azure.ai.evaluation</code> package to run a built-in evaluator (GroundednessEvaluator) to score the responses from the target app.</li> <li>If both the data (test) and target (function) are provided, it will first invoke the target with that data - and then run evaluations on the results.</li> <li>If <code>azure_ai_project</code> is set, then the evaluation results are also logged to Azure AI Foundry</li> </ul> src/api/evaluate.py<pre><code>    # ----------------------------------------------\n    # 4. Run the Evaluation\n    #    View Results Locally (Saved as JSON)\n    #    Get Link to View Results in Foundry Portal\n    #    NOTE:\n    #    Evaluation takes more tokens \n    #    Try to increase Rwate limit (Tokens per minute)\n    #    Script should handle limit errors if needed\n    # ----------------------------------------------\n    # Evaluate must be called inside of __main__, not on import\n\n    if __name__ == \"__main__\":\n        from config import ASSET_PATH\n\n        # workaround for multiprocessing issue on linux\n        from pprint import pprint\n        from pathlib import Path\n        import multiprocessing\n        import contextlib\n\n        with contextlib.suppress(RuntimeError):\n            multiprocessing.set_start_method(\"spawn\", force=True)\n\n        # run evaluation with a dataset and target function, \n        # log to the project\n        result = evaluate(\n            data=Path(ASSET_PATH) / \"chat_eval_data.jsonl\",\n            target=evaluate_chat_with_products,\n            evaluation_name=\"evaluate_chat_with_products\",\n            evaluators={\n                \"groundedness\": groundedness,\n            },\n            evaluator_config={\n                \"default\": {\n                    \"query\": {\"${data.query}\"},\n                    \"response\": {\"${target.response}\"},\n                    \"context\": {\"${target.context}\"},\n                }\n            },\n            azure_ai_project=project.scope,\n            output_path=\"./myevalresults.json\",\n        )\n\n        tabular_result = pd.DataFrame(result.get(\"rows\"))\n\n        pprint(\"-----Summarized Metrics-----\")\n        pprint(result[\"metrics\"])\n        pprint(\"-----Tabular Result-----\")\n        pprint(tabular_result)\n        pprint(f\"View evaluation results in AI Studio: {result['studio_url']}\")\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/03/","title":"4.3 Configure Evaluation Model","text":"<p>Recall that in the last section, the evaluation script identified an evaluator_model that will serve as the judge AI for this assessment. </p>"},{"location":"Sample-Workshop/4-Evaluate/03/#1-specifying-evaluator-model","title":"1. Specifying Evaluator Model","text":"<p>In this workshop, we are reusing the same model for both chat_completion and evaluation roles, but you can choose to separate the two by:</p> <ul> <li>Deploying a new model to the same Azure AI Project</li> <li>Updating the <code>EVALUATION_MODEL</code> environment variable to this one</li> <li>Restarting the evaluation script</li> </ul> <p>HOMEWORK: Try deploying a <code>gpt-4</code> model for evaluations. How do results differ?</p> src/api/evaluate.py<pre><code>    # ----------------------------------------------\n    # 2. Define Evaluator Model to use\n    # ----------------------------------------------\n    evaluator_model = {\n        \"azure_endpoint\": connection.endpoint_url,\n        \"azure_deployment\": os.environ[\"EVALUATION_MODEL\"],\n        \"api_version\": \"2024-06-01\",\n        \"api_key\": connection.key,\n    }\n\n    groundedness = GroundednessEvaluator(evaluator_model)\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/03/#2-configuring-evaluator-model","title":"2. Configuring Evaluator Model","text":"<p>Let's take a look at the core <code>evaluate</code> function that executes the workflow. This function will run an assessment once for each record (in <code>data</code>), for each evaluator (in <code>evaluators</code>). This requires a lot of calls to the identified evaluation model - which will require a higher token capacity for efficient completion.</p> <p>Note: The current script uses a single evaluator (for Groundedness). Adding additional evaluators will increase the number of calls made to the default model, so make sure you configure quota to adjust for that accordingly.=</p> <p>Update the model quota in Azure AI Foundry if execution has rate limit issues</p> <p>Take these steps to view and update your model quota.</p> <ul> <li>Visit your Azure AI project page in Azure AI Foundry</li> <li>Click \"Models + Endpoints\" and select the evaluation model</li> <li>Click <code>Edit</code> and increase the Tokens per minute rate limit* (e.g., to 30)</li> <li>Click <code>Save and close</code> </li> </ul> Click to expand and see a screenshot of the update dialog <p></p>"},{"location":"Sample-Workshop/4-Evaluate/04/","title":"4.4 Run Evaluation Script","text":"<p>To run the evaluation script from the Visual Studio Code terminal:</p> <ul> <li>You need to be authenticated on Azure</li> <li>You need to have the <code>azure-ai-evaluation</code> package installed</li> </ul> <p>You should have done the first step at the start of this workshop. The dev container has package installed already.</p>"},{"location":"Sample-Workshop/4-Evaluate/04/#1-run-the-script","title":"1. Run the Script","text":"<p>Run the script from the <code>src/api</code> folder). </p> <ol> <li> <p>Change to the <code>src/api</code> folder </p> <pre><code>cd src/api\n</code></pre> </li> <li> <p>Run the script:</p> </li> </ol> <pre><code>python evaluate.py\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/04/#2-observe-the-output","title":"2. Observe the Output","text":"<ul> <li>Note that there are 13 response records corresponding to the 13 test inputs in our evaluation dataset. These reflect the first stage of evaluation flow where the target AI (chat app) is creating a responses file based on the test inputs given.</li> <li>Note that you can view the traces in local device at the URL provided. This will launch a local version of the trace viewer.</li> </ul> <pre><code>Starting prompt flow service...\nStart prompt flow service on 127.0.0.1:23333, version: 1.16.2.\nYou can stop the prompt flow service with the following command:'pf service stop'.\n\nYou can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=main_evaluate_chat_with_products_rxna_3r9_20241216_163719_733780\n[2024-12-16 16:37:42 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run main_evaluate_chat_with_products_rxna_3r9_20241216_163719_733780, log path: /home/vscode/.promptflow/.runs/main_evaluate_chat_with_products_rxna_3r9_20241216_163719_733780/logs.txt\n\ud83d\udcac Response: {'content': 'Could you please specify which camping table you are referring to? There are multiple options available, and I can provide information on them.', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': \"Could you specify what aspect of care you're asking about? Are you looking for cleaning instructions, storage tips, or something else for the TrailWalker Hiking Shoes?\", 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': \"Could you please specify which tents you are comparing, or do you want information about a specific tent's waterproof features?\", 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'The TrailBlaze Hiking Pants are crafted from high-quality nylon fabric.', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'The TrailMaster X4 Tent comes with an included carry bag, which makes transporting the tent easy and convenient. You can simply pack the tent into the carry bag and carry it as needed for your camping adventure. If you have any more specific questions about the tent or its features, feel free to ask!', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n...\n...\n...\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/04/#3-rate-limit-errors","title":"3. Rate Limit Errors","text":"<p>Occasionally you might see an error message that looks like this. This relates to the tokens per minute rate limits on your evaluation model deployment. The script is designed to handle them and continue running - reconfiguring the model can help.</p> <pre><code>[2024-12-16 16:44:07 +0000][promptflow.core._prompty_utils][ERROR] - Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-06-01 have exceeded token rate limit of your current AIServices S0 pricing tier. Please retry after 60 seconds. Please contact Azure support service if you would like to further increase the default rate limit.'}}\n[2024-12-16 16:44:07 +0000][promptflow.core._prompty_utils][WARNING] - RateLimitError #2, Retry-After=60, Back off 60.0 seconds for retry.\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/04/#4-final-result","title":"4. Final Result","text":"<p>Once the evaluation workflow completes, you should see a run summary that looks like this. Note that the evaluation results are saved locally, and also published to the Azure AI Foundry portal.</p> <pre><code>======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rvrjml8t_20241216_164205_696721\"\nRun status: \"Completed\"\nStart time: \"2024-12-16 16:42:05.695977+00:00\"\nDuration: \"0:03:06.490785\"\nOutput path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rvrjml8t_20241216_164205_696721\"\n\n======= Combined Run Summary (Per Evaluator) =======\n\n{\n    \"groundedness\": {\n        \"status\": \"Completed\",\n        \"duration\": \"0:03:06.490785\",\n        \"completed_lines\": 13,\n        \"failed_lines\": 0,\n        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rvrjml8t_20241216_164205_696721\"\n    }\n}\n\n====================================================\n\nEvaluation results saved to \"/workspaces/learns-azure-ai-foundry/src/api/myevalresults.json\".\n\n'-----Summarized Metrics-----'\n{'groundedness.gpt_groundedness': 1.4615384615384615,\n'groundedness.groundedness': 1.4615384615384615}\n'-----Tabular Result-----'\n                                    outputs.response  ... line_number\n0   Could you please specify which tents you are c...  ...           0\n1   Could you please specify which camping table y...  ...           1\n2   Sorry, I only can answer queries related to ou...  ...           2\n3   Could you specify what aspect of care you're a...  ...           3\n4   Sorry, I only can answer queries related to ou...  ...           4\n5   The TrailMaster X4 Tent comes with an included...  ...           5\n6   Sorry, I only can answer queries related to ou...  ...           6\n7   The TrailBlaze Hiking Pants are crafted from h...  ...           7\n8   Sorry, I only can answer queries related to ou...  ...           8\n9   Sorry, I only can answer queries related to ou...  ...           9\n10  Sorry, I only can answer queries related to ou...  ...          10\n11  Sorry, I only can answer queries related to ou...  ...          11\n12  Sorry, I only can answer queries related to ou...  ...          12\n\n[13 rows x 8 columns]\n('View evaluation results in AI Studio: '\n'https://ai.azure.com/build/evaluation/XXXXXXX?wsid=/subscriptions/XXXXXXXX/resourceGroups/ninarasi-ragchat-rg/providers/Microsoft.MachineLearningServices/workspaces/ninarasi-ragchat-v1')\n'''\n\n# ----------------------------------------------\n</code></pre>"},{"location":"Sample-Workshop/4-Evaluate/05/","title":"4.5 View Results Locally","text":"<p>In the previous section, we noticed that the console provided a truncated summary of the results of the evaluation run. But what if you wanted to see the details or observe the traces for these runs? You have two options - local or Azure AI Foundry portal.</p>"},{"location":"Sample-Workshop/4-Evaluate/05/#1-view-traces-locally","title":"1. View Traces Locally","text":"<p>The console log from the execution run will show you a trace viewer link URL:</p> <pre><code>You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=main_evaluate_chat_with_products_rxna_3r9_20241216_163719_733780\n</code></pre> <p>Navigate to that link in your browser, and you should get a trace viewer landing page that looks like this, with Traces and Collections.</p> <p></p> <p>If Traces stays on status Running, try switching to Collections and back to force a Refresh.</p> <p>Click on Traces - you should now be able to see records for the trace runs for each invocation of the chat application, with timestamps for each run.</p> <p></p> <p>Click on any row in the table to get the detailed trace view for that run - where you can drive into the call stack to understand the time taken for each call, the tokens consumer, and the inputs and outputs from each processing step.</p> <p>COMPARE IT: Contrast the local trace view to the Azure Foundry Portal view  seen earlier. How are they different?</p> <p></p>"},{"location":"Sample-Workshop/4-Evaluate/05/#2-view-results-locally","title":"2. View Results Locally","text":"<p>The evaluation run provides us a summary of results in the console, but it is truncated and hard to analyze. However, observe that the results are also stored in a local JSON file that you can open up in the Visual Studio Code IDE for exploration.</p> <p>Check out the <code>src.sample/api/myevalresults.json</code> for a sample file showing the outputs from a previous run. The snippet below reproduces one of the rows from those results - let's see what that provides:</p> <ol> <li>The <code>inputs.query</code> and <code>inputs.truth</code> are from the test input file</li> <li>The <code>outputs.context</code> reflects retrieved product documents used (RAG)</li> <li>The <code>outputs.response</code> gives the target models returned response</li> <li>The <code>outputs.groundedness.groundedness</code> has a rating of 1 (not grounded)</li> <li>The <code>outputs.groundedness.groundedness_reaason</code> explains why (context unused)</li> </ol> <p>Note: While the response is not grounded in the context, it does in fact reflect our prompt template guidance to ask for clarifications on questions where the intent is not clear.</p> <p>Click to expand a view a sample row from <code>myevalresults.json</code></p> <pre><code>    {\n        \"outputs.response\": \"Could you please specify which tents you are comparing, or do you want information about a specific tent's waterproof features?\",\n        \"outputs.context\": [\n            [\n                {\n                    \"id\": \"8\",\n                    \"content\": \"Welcome to the joy of camping with the Alpine Explorer Tent! This robust, 8-person, 3-season marvel is from the responsible hands of the AlpineGear brand. Promising an enviable setup that is as straightforward as counting sheep, your camping experience is transformed into a breezy pastime. Looking for privacy? The detachable divider provides separate spaces at a moment's notice. Love a tent that breathes? The numerous mesh windows and adjustable vents fend off any condensation dragon trying to dampen your adventure fun. The waterproof assurance keeps you worry-free during unexpected rain dances. With a built-in gear loft to stash away your outdoor essentials, the Alpine Explorer Tent emerges as a smooth balance of privacy, comfort, and convenience. Simply put, this tent isn't just a shelter - it's your second home in the heart of nature! Whether you're a seasoned camper or a nature-loving novice, this tent makes exploring the outdoors a joyous journey.\",\n                    \"filepath\": \"alpine-explorer-tent\",\n                    \"title\": \"Alpine Explorer Tent\",\n                    \"url\": \"/products/alpine-explorer-tent\"\n                },\n                {\n                    \"id\": \"15\",\n                    \"content\": \"Introducing the OutdoorLiving SkyView 2-Person Tent, a perfect companion for your camping and hiking adventures. This tent offers a spacious interior that houses two people comfortably, with room to spare. Crafted from durable waterproof materials to shield you from the elements, it is the fortress you need in the wild. Setup is a breeze thanks to its intuitive design and color-coded poles, while two large doors allow for easy access. Stay organized with interior pockets, and store additional gear in its two vestibules. The tent also features mesh panels for effective ventilation, and it comes with a rainfly for extra weather protection. Light enough for on-the-go adventurers, it packs compactly into a carrying bag for seamless transportation. Reflective guy lines ensure visibility at night for added safety, and the tent stands freely for versatile placement. Experience the reliability of double-stitched seams that guarantee increased durability, and rest easy under the stars with OutdoorLiving's SkyView 2-Person Tent. It's not just a tent; it's your home away from home.\",\n                    \"filepath\": \"skyview-2-person-tent\",\n                    \"title\": \"SkyView 2-Person Tent\",\n                    \"url\": \"/products/skyview-2-person-tent\"\n                },\n                {\n                    \"id\": \"1\",\n                    \"content\": \"Unveiling the TrailMaster X4 Tent from OutdoorLiving, your home away from home for your next camping adventure. Crafted from durable polyester, this tent boasts a spacious interior perfect for four occupants. It ensures your dryness under drizzly skies thanks to its water-resistant construction, and the accompanying rainfly adds an extra layer of weather protection. It offers refreshing airflow and bug defence, courtesy of its mesh panels. Accessibility is not an issue with its multiple doors and interior pockets that keep small items tidy. Reflective guy lines grant better visibility at night, and the freestanding design simplifies setup and relocation. With the included carry bag, transporting this convenient abode becomes a breeze. Be it an overnight getaway or a week-long nature escapade, the TrailMaster X4 Tent provides comfort, convenience, and concord with the great outdoors. Comes with a two-year limited warranty to ensure customer satisfaction.\",\n                    \"filepath\": \"trailmaster-x4-tent\",\n                    \"title\": \"TrailMaster X4 Tent\",\n                    \"url\": \"/products/trailmaster-x4-tent\"\n                },\n                {\n                    \"id\": \"14\",\n                    \"content\": \"Meet the MountainDream Sleeping Bag: your new must-have companion for every outdoor adventure. Designed to handle 3-season camping with ease, it comes equipped with a premium synthetic insulation that will keep you cozy even when temperatures fall down to 15\\u00b0F! Sporting a durable water-resistant nylon shell and soft breathable polyester lining, this bag doesn't sacrifice comfort for toughness. The star of the show is the contoured mummy shape that not only provides optimal heat retention but also cuts down on the weight. A smooth, snag-free YKK zipper with a unique anti-snag design allows for hassle-free operation, while the adjustable hood and full-length zipper baffle work together to ensure you stay warm all night long. Need to bring along some essentials? Not to worry! There's an interior pocket just for that. And when it's time to pack up? Just slip it into the included compression sack for easy storage and transport. Whether you're a backpacking pro or a camping novice, the MountainDream Sleeping Bag is the perfect blend of durability, warmth, and comfort that you've been looking for.\",\n                    \"filepath\": \"mountaindream-sleeping-bag\",\n                    \"title\": \"MountainDream Sleeping Bag\",\n                    \"url\": \"/products/mountaindream-sleeping-bag\"\n                },\n                {\n                    \"id\": \"9\",\n                    \"content\": \"Adventure waits for no one! Introducing the HikeMate SummitClimber Backpack, your reliable partner for every exhilarating journey. With a generous 60-liter capacity and multiple compartments and pockets, packing is a breeze. Every feature points to comfort and convenience; the ergonomic design and adjustable hip belt ensure a pleasantly personalized fit, while padded shoulder straps protect you from the burden of carrying. Venturing into wet weather? Fear not! The integrated rain cover has your back, literally. Stay hydrated thanks to the backpack's hydration system compatibility. Travelling during twilight? Reflective accents keep you visible in low-light conditions. The SummitClimber Backpack isn't merely a carrier; it's a wearable base camp constructed from ruggedly durable nylon and thoughtfully designed for the great outdoors adventurer, promising to withstand tough conditions and provide years of service. So, set off on that quest - the wild beckons! The SummitClimber Backpack - your hearty companion on every expedition!\",\n                    \"filepath\": \"summitclimber-backpack\",\n                    \"title\": \"SummitClimber Backpack\",\n                    \"url\": \"/products/summitclimber-backpack\"\n                }\n            ]\n        ],\n        \"inputs.query\": \"Which tent is the most waterproof?\",\n        \"inputs.truth\": \"The Alpine Explorer Tent has the highest rainfly waterproof rating at 3000m\",\n        \"outputs.groundedness.groundedness\": 1,\n        \"outputs.groundedness.gpt_groundedness\": 1,\n        \"outputs.groundedness.groundedness_reason\": \"The RESPONSE does not reference any of the tents or their features from the CONTEXT, making it completely ungrounded. It fails to provide any relevant information or insights based on the provided material.\",\n        \"line_number\": 0\n    },\n</code></pre> <p>But local results are not persistent in a way that helps us compare or process data over long periods of time. This is where having the Evaluations output stored in Azure AI Foundry portal can help.</p>"},{"location":"Sample-Workshop/4-Evaluate/06/","title":"4.6 View Results In Portal","text":"<p>In the previous step, we looked at the traces and evaluation results in the local environment. However, we configured our evaluation script to also push the results to the Azure AI Foundry portal.  Let's take a look at how those results are visualized.</p>"},{"location":"Sample-Workshop/4-Evaluate/06/#1-evaluations-tab-on-portal","title":"1. Evaluations Tab On Portal","text":"<p>Navigate to the Azure AI project page in Azure AI Portal, and select the Evaluation item on the sidebar. You should see an evaluations landing page like this, with the latest evaluation run listed in the table. The list entry shows the average Groundedness score for that run.</p> <p></p>"},{"location":"Sample-Workshop/4-Evaluate/06/#2-evaluations-results-on-portal","title":"2. Evaluations Results On Portal","text":"<p>Click on the evaluations run in the list to get this detailed dashboard view:</p> <ul> <li>The Evaluation details section give overall status. Click the <code>raw JSON</code> link to dive deeper.</li> <li>The Metrics dashboard visualizes AI Quality metrics and supports Custom charts.</li> <li>The Detailed metrics result shows evaluation results in tabular form (with search &amp; filters)</li> </ul> <p>Use the metrics dashboard to get a visual understanding of how the metrics are distributed across the evaluation results. For instance, we can see that in our evaluation, 11 responses were considered ungrounded and 2 were given a groundedness score of 4. However, this does not give us insight into why those scores were given.</p> <p></p>"},{"location":"Sample-Workshop/4-Evaluate/06/#3-explore-detailed-metrics","title":"3. Explore Detailed Metrics","text":"<p>This is where the detailed metrics help. We can browse through the results in tabular form, or we can drill down into the evaluations for a specific query or product using search. In this example, we see that the TrailMaster product was relevant to at least 3 of the 13 queries - but the scores ranged from 1 (low groundedness) to 4 (high groundedness).</p> <p></p> <p>However, with this view, we can drill down into the reasons for the score, and take follow up actions to improve it. For instance:</p> <ol> <li> <p>The first query received a low score of 1 because the response did not reference any of the tents in the provided context. But if we look deeper, we may notice that the response is actually reflecing the instructions provided in our system context - so in this case, the response was not grounded, but was relevant. </p> src/assets/grounded_chat.prompty<pre><code>system:\nYou are an AI assistant helping users with queries related to outdoor outdooor/camping gear and clothing.\nIf the question is not related to outdoor/camping gear and clothing, just say 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?'\nDon't try to make up any answers.\nIf the question is related to outdoor/camping gear and clothing but vague, ask for clarifying questions instead of referencing documents. If the question is general, for example it uses \"it\" or \"they\", ask the user to specify what product they are asking about.\nUse the following pieces of context to answer the questions about outdoor/camping gear and clothing as completely, correctly, and concisely as possible.\nDo not add documentation reference in the response.\n</code></pre> </li> <li> <p>The second query received a low score of 1 which appears justified again. In this case, we note that the response reflects instructions related to questions that are off-topic - so this may be a place to investigate =why the question is seen as off-topic despite mentioning a product in the list.</p> </li> <li> <p>The third query received a high score of 5 which again looks valid, given the reasoning of this being incomplete. However, if we look at the truth and compare it to the response, we may find that it meets our expectations - and lead us to refining the evaluation prompt that defines the scoring criteria.</p> </li> </ol>"},{"location":"Sample-Workshop/4-Evaluate/06/#4-build-custom-charts","title":"4. Build Custom Charts","text":"<p>One of the value propositions of using the Azure AI Foundry portal is the ability to create custom charts based on the evaluation results. Click the <code>Custom</code> tab and walk through the creation dialog to add visuals that reflect specific views into the data. For example, this view helps us see that a disproportionate number of responses were in the <code>Sorry, I only can answer queries related to ..</code> category, indicating that we may need to refine our chat prompt template guidance to ensure we are not rejecting valid queries.</p> <p></p>"},{"location":"Sample-Workshop/4-Evaluate/06/#5-try-more-evaluators","title":"5. Try More Evaluators","text":"<p>The Azure AI Foundry platform has an Evaluator library with an extensive list of built-in evaluators that cover risk &amp; safety, performance &amp; quality assessment. </p> <p></p> HOMEWORK: Try adding more evaluators to the script <p>To use a named evaluator - update the <code>evaluate.py</code> script to import the selected options as shown below.</p> <ol> <li> <p>Import the evaluators     <pre><code>from azure.ai.evaluation import F1ScoreEvaluator, RelevanceEvaluator, ViolenceEvaluator\n</code></pre></p> </li> <li> <p>Configure them with the chosen evaluation model</p> <pre><code>evaluator_model = {\n    \"azure_endpoint\": connection.endpoint_url,\n    \"azure_deployment\": os.environ[\"EVALUATION_MODEL\"],\n    \"api_version\": \"2024-06-01\",\n    \"api_key\": connection.key,\n}\nf1score = F1ScoreEvaluator(evaluator_model)\nrelevance = RelevanceScoreEvaluator(evaluator_model)\nviolence = ViolenceScoreEvaluator(evaluator_model)\n</code></pre> </li> <li> <p>Specify them in the call to the evaluate function</p> <pre><code>result = evaluate(\n    data=Path(ASSET_PATH) / \"chat_eval_data.jsonl\",\n    target=evaluate_chat_with_products,\n    evaluation_name=\"evaluate_chat_with_products\",\n    evaluators={\n        \"groundedness\": groundedness,\n    },\n    evaluator_config={\n        \"default\": {\n            \"query\": {\"${data.query}\"},\n            \"response\": {\"${target.response}\"},\n            \"context\": {\"${target.context}\"},\n        }\n    },\n    azure_ai_project=project.scope,\n    output_path=\"./myevalresults.json\",\n)\n</code></pre> </li> </ol>"},{"location":"Sample-Workshop/5-Evolve/01/","title":"5.1 Recap: Build A Copilot","text":"<p>CONGRATULATIONS! You just learn to use the Azure AI Foundry platform to build a RAG-based copilot</p>"},{"location":"Sample-Workshop/5-Evolve/01/#1-what-you-learned-today","title":"1. What You Learned Today","text":"<p>By completing the workshop, you gained three things:</p> <ol> <li>You have a working knowledge of how to build a RAG-based copilot.</li> <li>You have a working familiarity with the Azure AI Foundry platform.</li> <li>You have a functional sandbox in this repo, to experiment further.</li> </ol>"},{"location":"Sample-Workshop/5-Evolve/01/#2-where-can-you-go-next","title":"2. Where Can You Go Next?","text":"<p>Take advantage of this repository and GitHub Codespaces environment to start exploring the Azure AI Platform portal, SDK and tooling, in more intentional ways.</p>"},{"location":"Sample-Workshop/5-Evolve/01/#21-setup","title":"2.1 Setup","text":"<ol> <li>The Azure AI Foundry Architecture</li> <li>Management Center</li> <li>Azure AI Foundry SDK</li> <li>How To: Create a project in Azure AI Foundry portal</li> <li>How To: Create and manage an Azure AI Foundry Hub</li> <li>How To: Deploy AI Models in Azure AI Foundry</li> </ol>"},{"location":"Sample-Workshop/5-Evolve/01/#22-ideate","title":"2.2 Ideate","text":"<ol> <li>Quickstart: Use the Chat Playground</li> <li>Quickstart: Build a Chat App using Azure AI SDK</li> <li>Quickstart: Get Started Using Azure OpenAI Assistants</li> <li>Tutorial Build a custom chat app with the Azure AI Foundry SDK</li> </ol>"},{"location":"Sample-Workshop/5-Evolve/01/#23-evaluate","title":"2.3 Evaluate","text":"<ol> <li>Evaluation of generative AI applications</li> <li>Evaluation and monitoring metrics for generative AI</li> <li>How To: Generate synthetic and simulated data for evaluation</li> <li>How To: Evaluate your Generative AI application with the Azure AI Evaluation SDK</li> <li>How To: Evaluate Generative AI models and applications with Azure AI Foundry Portal</li> <li>Tracing in Azure AI Inference SDK overview</li> <li>How To: Trace your application with Azure AI Inference SDK</li> <li>How To: Visualize your traces</li> </ol>"},{"location":"Sample-Workshop/5-Evolve/01/#24-deploy","title":"2.4 Deploy","text":"<ol> <li>Deploy an enterprise chat web app</li> <li>Azure AI App Templates</li> </ol>"},{"location":"Sample-Workshop/5-Evolve/02/","title":"5.2 Refactor: Make it Better","text":""},{"location":"Sample-Workshop/5-Evolve/02/#1-contoso-chat-sample","title":"1. Contoso Chat Sample","text":"<p>Once you've familiarized yourself with the basic setup, ideation and evaluation capabilities, you can explore the Contoso Chat sample for more advanced insights, on your own. </p> <p>This sample uses the same retail dataset used in this RAG Chat workshop, but streamlines the end-to-end development workflow with core developer tools like Azure Developer CLI, to automate provisioning and deployment. The sample also teaches you how to package up your application prototype and deploy it into production using Azure Container Apps.</p> <p>The Contoso Chat Workshop walks you through the end-to-end development journey from prompt to production, using an AI App template that can be provisioned and deployed with a single command (<code>azd up</code>). The sample also shows you how to use a FastAPI application server (to create an API endpoint for accepting requests to our chat AI) and how to package up the application as a Docker container that can be deployed to an Azure Container Apps endpoint for real-world interactions.</p> <p></p> <p>Contoso Chat is currently in v3. An updated v4 (Jan 2025) will reflect recent Azure AI SDK updates</p>"},{"location":"Sample-Workshop/5-Evolve/02/#2-rag-chat-sample-v2","title":"2. RAG Chat Sample (v2)","text":"<p>Another option is to use this existing repository and workshop as a sandbox sample that you can customize to your own requirements. Here are some suggestions for ways to experiment further:</p> <ol> <li> <p>Bring Your Own Data - Walk through the steps but replace the <code>product.csv</code> with your data, and understand the implications for all the other steps in the workflow. For example - you will need to create a new set of evaluation test inputs (for your use case) and refactor the prompt templates (for intent mapping and chat-with-products) to reflect new instructions or context.</p> </li> <li> <p>Integrate More Sources - The basic sample has a single data source (product catalog index). However, the <code>data/</code> folder provides additional data sources (customer data, product manual data) that can be used for even richer experiences. Think of how you can refactor the existing code to support data retrieval from multiple sources that store this data (e.g., Customer data in Azure Cosmos DB).</p> </li> <li> <p>Write Custom Evaluators - The default evaluators for quality reflect common best practices. However, you may want to assess responses for a custom criteria. Think of how you can write a custom evaluator, and add it into the evalution script. For example: evaluate responses for politeness or for being kid-friendly.</p> </li> <li> <p>Explore Richer RAG Patterns - The core of RAG patterns is the retrieval of relevant knowledge from various sources including Azure AI Search. Explore new algorithms or ways of combining context to make the retrieved documents more relevant to application needs.</p> </li> <li> <p>Make it Agentic - Agentic workflows are dominating the AI ecosystem today. Agentic RAG refers to the use of AI agents for information retrieval where the agent mediates between multiple data sources to drive enhanced RAG pipelines for delivery. Read more here.</p> </li> </ol>"},{"location":"Sample-Workshop/6-Cleanup/","title":"6. Cleanup \ud83d\udea8","text":"<p>We deployed AI models and an AI search resource. We used GitHub Codespaces for development. These can incur unnecessary costs or quota usage if left running. LET'S CLEAN THIS UP NEXT!</p>"},{"location":"Sample-Workshop/6-Cleanup/#1-delete-github-codespaces","title":"1. Delete GitHub Codespaces","text":"<p>Github Codespaces has a free tier for personal accounts with 15GB storage and 120 Core hours per month. This quota is more than sufficient for running this workshop, but leaving the Codespaces running  will use up that quota unnecessarily.</p> <p>Let's delete the active codespaces.</p> <ol> <li>Visit Your Codespaces page on GitHub.</li> <li>Scroll to see the Owned by [username] section. For example: the screenshot shows the section <code>Owned by nitya</code> listing my codespaces.</li> <li>Identify the GitHub Codespaces instance used for this workshop by checking the repo name shown above the codespaces name. For example: the screenshot shows <code>nitya/azure-ai-rag-workshop</code> as the repo for the <code>fluffy system</code> codespace.</li> </ol> <p></p> <p>The codespace may show unsaved changes (see: <code>main*</code> under codespaces name, where the <code>*</code> indicates you have unsaved changes on the main branch). You can commit these changes to save your workshop progress, or you can ignore them to retain the original workshop. </p> <p>Let's delete the codespace. Click the <code>...</code> icon to get the drop-down menu as shown below. You now have the option to Stop codespace or Delete it (last option in list). I recommend you Delete it since this is just a learning workshop. You can always start a new Codespace later.</p> <p>Congratulations! You deleted your GitHub Codespaces!</p>"},{"location":"Sample-Workshop/6-Cleanup/#2-delete-resource-group","title":"2. Delete Resource Group","text":"<p>The workshop would have resulted in the deployment of an Azure AI hub and project resource, along with supporting Azure AI services and resources like Azure AI Search, Azure OpenAI, and Application Insights. </p> <p>Let's delete these resources now</p> <ol> <li>Visit the Azure AI Foundry Portal and log in.</li> <li>Visit the Azure AI project page for this workshop.</li> <li>Click on the Management Center in sidebar (bottom, left)</li> <li>You should see something like this - click on the Resource Group link.     </li> <li>You should be redirected to the Azure Portal and see something like this:     </li> <li>Click the Delete resource group and complete the workflow.</li> <li>Deletion will take a few minutes to complete (watch the status bar).</li> <li>When completed, refresh screen to verify Resource Group was deleted.</li> </ol> <p>Congratulations! You deleted your Resource Group!</p>"},{"location":"Sample-Workshop/6-Cleanup/#3-purge-deleted-resources","title":"3. Purge Deleted Resources","text":"<p>When you delete an Azure AI services resource, you may encounter a soft delete issue where the resource is not completely purged by default. This can have two implications:</p> <ol> <li>Associated model quota is not released, affecting your ability to reuse it.</li> <li>You cannot create another resource with the same name for 48 hours.</li> </ol> <p>You can address these by manually purging deleted Azure AI services resources using the Azure portal, Azure CLI or Rest API options. Let's use the Azure Portal approach.</p> <ol> <li>Navigate to the Azure Portal and log in.</li> <li>You should see something like this. Click on the <code>Azure AI Services</code> icon.     </li> <li>You should see something like this. Click on the <code>Azure AI services</code> sidebar option.     </li> <li>You should see something like this. Click on the <code>Manage deleted resources</code> option in the menu to get the slideout panel seen at the right.     </li> <li>Make sure the subscription is set to the right one from the workshop. Any deleted resources that have not been purged will be listed here. You can then select and complete the workflow to release those resources for reuse. </li> </ol> <p>If the resource included model quota you can verify the quota was released by looking up the Management Center / Model quota tab in the Azure AI Foundry portal.</p> <p>Congratulations! You purged any soft-deleted Azure AI resources!</p> <p>Your cleanup is complete. \u2705</p>"}]}